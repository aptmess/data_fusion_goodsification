{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Fusion Contest\n",
    "\n",
    "## Решение задачи `Goodsification`\n",
    "\n",
    "* February 2021 - March 2021\n",
    "* Александр Широков, [github](https://github.com/aptmess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_to_file):\n",
    "    train = pd.read_parquet(path_to_file)\n",
    "    map_column_to_type = {\n",
    "        'category_id': np.int16,\n",
    "        'item_nds_rate': np.int16,\n",
    "        'item_price': np.int16,\n",
    "        'item_quantity': np.float32,\n",
    "        'receipt_dayofweek': np.int16,\n",
    "        'receipt_id': np.int32}\n",
    "    for key in map_column_to_type:\n",
    "        train[key] = train[key].astype(map_column_to_type[key])\n",
    "    train = train.drop('brands', axis=1)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data_name = '../data/data_fusion_train.parquet'\n",
    "train = load_data(train_data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим размеченные категории товаров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train[train['category_id'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В своей работе я сделал ставку на предобработку текста и выуживание из него тех незаметных вещей, которые простые `regex` или токенизация не смогут найти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Предобработка текста - внимание к мелочам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит понимать, что при работе с чеками мы работаем не с обычным текстом, а с ужасно зашумлённым и непредобработанным. Поюсню это на основных моментах, которые учитывались при предобработке текста:\n",
    "\n",
    "1. Достаём слова из текста\n",
    "\n",
    "Опишем возможные ситуации, которые встречаются в тексте.\n",
    "\n",
    "- неразделенные слова, например: `КормДляКошек` (*корм для кошек*) или `презервативыdurex` (*презервативы durex*)\n",
    "- неразделенные слова, но с опечатками/сокращениями внутри, например: `кормдкошек` (*корм для кошек*) - необходимо построить алгоритм поиска опечаток в словах\n",
    "- кстати про опечатки, они могут быть и в одиночных словах, так что это тоже стоит учитывать\n",
    "- всевозможные сокращения одного и того же слова, например, слово шампунь в чеках сокращалось 6-ую различными способами:\n",
    "`ш-нь, ш/нь, шамп., шампн., шампун., шмпнь` и это, наверное, не всё. Так же сокращения нужно применять тоже осторожно, полагаясь на контекст, потому что `шамп` может оказаться и *шампанским*. Таким образом необходимо построить алгоритм по сокращенному слову пытаться предсказывать его нормальную форму.\n",
    "- слова могут применяться по-разному в разных контекстах, например слово *краска* применялось в нескольких категориях - строительные материалы, рисование, цветы\n",
    "- английские слова часто могут быть подсказкой для определенной категории, поэтому их стоит хотя бы не выбрасывать: `например`, в `101` категории, представляющая из себя спортивное питание, было несколько компаний, которые связаны только со спортивным питанием\n",
    "- стоит отметить, что кажущиеся бессмысленными некоторые слова могут являться *аббревиатурой*, из которой можно много понять о категории чека. Например, в `92` категории есть очень много таких слов, например `хвс`: `холодное водоснабжение`, `жбо` - жидко бытовые отходы;\n",
    "- еще важно при парсинге слов искать различные сокращения вида `<буква>/<буква>`, для примера `б/а` - *безалкогольный*, а `х/к` - холодное копчение и.т.д - таких слов очень много и их тоже надо пытаться как-то понимать.\n",
    "- для трудно разделимых категорий можно попытаться понять общий смысл у слов в этой категории и попытаться добавить ключевое слово к каждому встречающемуся. Так, например, `90` категория была представлена очень малым количеством уникальных чеков, однако из слов `выходной, боулинг, бенгальский, батут, дискотека` можно было понять, что речь идет о каком-то отдыхе или празднике и добавить в список слов `праздник`, `удовольствие`, что позволяет лучше разделять классы между собой\n",
    "\n",
    "- при парсинге в лоб легко упустить какие-то мелочи: так, например в `7` и `9` категориях были представлены лишь какие-то двухбуквенные слова в перемешку с цифрами, по типу `АИ-92-k5` и при обработке текста в данной строке не найдется ничего полезного. Однако информации здесь очень много: данная абревиатура свойственна заправочным станциям, которые продают (евро) топливо на газовых голоках. Такие ситуации можно решать с помощью `regex` шаблонов: \n",
    "\n",
    ">  ```python\n",
    "import re\n",
    "s = \"[аи|а|a|aи]{1,}[- ][0-9]{2,}[\\w\\/]{1,}[- ][0-9]{2,}[- ]\\w\\d|\n",
    "    [\\w\\/]{1,}[- ][0-9]{2,}-\\w\\d|\n",
    "    [аи|а|a|aи]{1,}[-+ | 0-9]{2,}[0-9a-zа-я]{2,}|\n",
    "    [аи|а|a|aи]{1,}[0-9]{2,}-\\w\\d|[аи|а|a|aи]{1,}[0-9-]{2,}|\n",
    "    трк|бензин|\"\n",
    "words = re.findall(r'{}'.format(s), z)```\n",
    "\n",
    "- некоторые слова сокращаются до одной буквы - это было очень неприятно.\n",
    "\n",
    "В итоге данные идеи могли помочь в предобработке текста и могут быть взяты на вооржуение в будущем. Задача расстановки пробелов или исправления опечаток в зашумлённых текстах - интересная и важная задача.\n",
    "\n",
    "2. Знаки препинания\n",
    "\n",
    "    - в чеках в этом плане творилась полная неразбериха. Слова могли сокращаться таким образом `стекл.очист. 200мл.д/т` и приходилось использовать какие-то хитрые сплиты - создавать шаблоны для сокращений `<word>/<word>`, проверять не сокращённое ли слово и.т.д\n",
    "    - иногда было важно то, что стоит в кавычках `\"<word>\"` или скобках `\"(word)\"`, это тоже стоит учитывать\n",
    "    \n",
    "3. Цифры\n",
    "\n",
    "    - с цифрами у меня был диалог короткий - я выуживал лишь наиболее встречающиеся конструкции, такие как `\\d+л|мл|ml` или та же самая конструкция, но с килограммами, милиграммами и их сокращениями\n",
    "    \n",
    "    \n",
    "В итоге собирался словарь сокращений и писалась по ходу огромная и очень коряво-написанная функция для преобразования текста с огромным количеством `regex` выражений и условий. Но главное было не в реализации, а в идеях - что можно выжать из текста. Для любителей кода я в конце ноутбука помещу его, но я заранее извиняюсь :)\n",
    "\n",
    "Примеры предобработки текста:\n",
    "\n",
    "\n",
    "    - INPUT: Спинки варено-копченые из мяса ЦБ в/у охладенные\n",
    "\n",
    "    - OUPTUT: спинки варено копченые из мяса цыпленок бройлер вакуумная упаковка охладенные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Классы товаров\n",
    "\n",
    "Каждый класс товара я просматривал отдельно для каждой категории, находя какие-то смысловые общие нагрузки или заменяя опечатки, которые нельзя заменить программно. Таким образом, спустя несколько дней обработки, я получил следующую таблицу категорий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `0` - алкогольная продукция\n",
    "- `1` - презерватиры\n",
    "- `2` - сигареты\n",
    "- `3` - стики, нагреваемые табачные палочки\n",
    "- `4` - автомобильная лампа\n",
    "- `6` - различные приборы чистки для авто: щётки, стеклоочистители\n",
    "- `7` - газовые колонки, топливо, заправка\n",
    "- `9` - дизельное топливо\n",
    "- `11` - щётка, услуги автомойки\n",
    "- `12` - масла, смазки, ароматизаторы, антифризы для автомобилей\n",
    "- `13` - ремонт машин\n",
    "- `19` - канцелярские принадлежности, бумага\n",
    "- `20` - газеты, журналы\n",
    "- `24` - детская литература, книжки для малышки\n",
    "- `26` - органайзеры, ножницы, листки, закладки, корректоры\n",
    "- `27` - обложки, вкладыши, папки\n",
    "- `29` - карандаши, ручки\n",
    "- `30` - тетради, дошкольные предметы, прописи\n",
    "- `31` - все для художников\n",
    "- `35` - эфирные масла и свечи\n",
    "- `36` - витамины, гематогены, капсулы\n",
    "- `37` - детские: подгузники, мыло детское, шампуни\n",
    "- `38` - таблетки\n",
    "- `39` - контактные линзы\n",
    "- `40` - туалетная бумага, зубная щетка, паста, тампоны\n",
    "- `41` - тональные крема, тушь, помада\n",
    "- `42` - лак для ногтей, маникюр, гель\n",
    "- `43` - тесты на беременность, шприцы, бахилы, бинты, катетеры\n",
    "- `45` - врач: узи, кт, зубной\n",
    "- `46` - парфюмерия, косметика, туалетная вода:\n",
    "- `49` - все для волос: шампуни, расчесчки.\n",
    "- `50` - различные маски, крема: для лица\n",
    "- `51` - мыла, масла, дезодорант: для тела\n",
    "- `52` - шапки, варежки, ремни...\n",
    "- `53` - просто брюки\n",
    "- `54` - куртки, плащи, фуфайки..\n",
    "- `55` - только джинсы \n",
    "- `56` - брюки, сорочки, шорты\n",
    "- `57` - обувь: туфли, ботинки, сандали, тапочки\n",
    "- `58` - платье + сарафан\n",
    "- `60` - толстовки, джемперы, кардиганы, кофты\n",
    "- `61` - колготки, майки, куча одежды\n",
    "- `62` - спортивная одежда, шорты, треники, перекрывается...\n",
    "- `66` - пицца \n",
    "- `67` - роллы, суши..\n",
    "- `68` - бургеры, сэндвичи, бутреброды..\n",
    "- `69` - байтсы, куриные ножки, чикенбургеры - видимо, курица и.т.д.\n",
    "- `70` - кофе их разновидности, чай, какао\n",
    "- `71` - рестораны продукты: можно парсить названия по составу продуктов: всевозможные продукты!!\n",
    "- `72` - детское питание: фруто няня, соки для детей, пюрешки\n",
    "- `73` - замороженная продукция: рыба, замороженное мясо, тесто, пельмени\n",
    "- `74` - колбаса, свинина, сервелаты\n",
    "- `75` - консервно баночная продукция: ананасы в банках, шпроты, соленья\n",
    "- `76` - крупы: макароны, греча, каши\n",
    "- `77` - соусы, кетчупы, масло подсолнечное\n",
    "- `78` - молочные продукты: сыр, молоко, творог и.т.д\n",
    "- `79` - вот тут уже мясо: шницели, языки, курица, стейки\n",
    "- `80` - овощи и фрукты\n",
    "- `81` - орехи, чипсы, сухарики, гренки, арахис + кукуруза, горошек\n",
    "- `82` - рыбы... очень много различной рыбы\n",
    "- `83` - напитки, соки\n",
    "- `84` - наиболее представительная категория - сладости, ватрушки, хлебобулочные изделия, шоколадки: очень много\n",
    "- `85` - чаи кофе - видимо, нужно смотреть на цену, потому что будет очень много пересечений с категорией `70` - абсолютно идентичные. Видимо, данная категория: *кофе в магазине*, а `70` - в *ресторанах*.\n",
    "- `90` - праздничные товары, веселье, хлопушки, различные удовольствия\n",
    "- `92` - `ЖКХ` услуги\n",
    "- `96` - мячи насосы\n",
    "- `97` - бассейн, билеты в бассейн, маски продажа, очки для плавания, прокат катамаранов, добавил данные\n",
    "- `100` - наколенники, шлема - защитные устройства для спорта\n",
    "- `101` - протеиновые батончики, набор массы, смеси\n",
    "- `102` - спортивное оборудование: `штанги, гантели`. добавил материалы\n",
    "- `103` - все для рыбалки, походов, палатки, \n",
    "- `105` - различные трубы, Отводки, муфты, прокладки, связанные с водой\n",
    "- `106` - дверные замки, петли, застежки дверей\n",
    "- `107` - плоскогупцы, шпатели, отвертки, напильники, малярные инструменты,  лобзики: строительные красящие\n",
    "- `108` - аэрозоли, растворители, анисептикик - смеси\n",
    "- `109` - гайки, болты, гвозди\n",
    "- `111` - сантехника водные:  фильтры для раковин и.т.д\n",
    "- `114` - суперклеи, изолента, наждачная бумага, герметик, изоляция, клеи, клейкая лента, рубероид\n",
    "- `115` - тройники, розетки, провода, предохранители, кабеля, выключатели: все, что связано с электричеством\n",
    "- `117` - освежители, перчатки, стирательные порошки, мыло, пятновывадительные: со стиркой связанные\n",
    "- `118` - фоторамки, украшения, шары, горшки, свечи - всякие нужные материалы для дома\n",
    "- `120` - игрушки для детей: `лего`, машинки, конструкторы и.т.д\n",
    "- `121` - пакет (это не категория, просто единственное слово в этой категории)\n",
    "- `128` - прожектора, светильники, лампы, светодиоды: все, что со светом связано\n",
    "- `130` - банки, бутылки, декоративные контейнеры, кружки, стаканчики, крышки, миски, прихватки, салатницы, тарелки: `столовые приборы`\n",
    "- `133` - полотенца, простыни, скатерти, салфетки, подушки, одеяла, наволочки - хлопчато-бумажные\n",
    "- `138` - уголь, шампуры, решетки, сетка, щепа, черенки, лопаты, жидкость для розжига\n",
    "- `139` - мешки для мусора, зажигалки, мешки полиэтиленовые, перчатки - все для уборки + зажигалки(\n",
    "- `140` - цветы (для посадки), семена цветов, грунт для земли\n",
    "- `143` - пакет (это не категория, просто единственное слово в этой категории)\n",
    "- `145` - корм для кошек\n",
    "- `150` - корм для собак\n",
    "- `163` - рисование, раскраски\n",
    "- `164` - пластилин, тесто для лепки, глина\n",
    "- `167` - все для вышивания, нитки, ленты, бусины, крючки, стразы, ткань\n",
    "- `177` - для телефона: батарейки, держатели для телефона, чехлы для телефона, штекеры, электронное питание телефона, кабель для телефона lighting usb\n",
    "- `203` - все, что связано с упаковкой товара, коробки, конверты, упаковочаня бумага, одноразовые упаковки, пакеты упаковочные\n",
    "- `204` - какие-то услуги, посещения, услуги, гости, акции, но такое ощущение, что это категория для неопределимого."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, тут собрано буквально всё, что есть в мире. Весьма различимы несколько кластеров - еда, продукты, одежда, товары для дома, декоративные товары, развлечения. Каждая подгруппа также делится по смыслу на категории, однако встречаются и наложения, которые тяжело отметить даже специалисту - например `204` категория собрала в себя всевозможные услуги, посещения, праздники, встречалась и еда и её было тяжело отделять, как тяжело отделять кофейную продукцию в ресторанах от кофейной продукции в магазинах (категории `70` и `85`). По результатам отмечу следующие наблюдения:\n",
    "\n",
    "- все категории, в которых было большое количество уникальных чеков (больше 1000) (кроме `204`), отлично отделялись\n",
    "- были и категории с небольшим количеством наблюдений, но с отличной разделимостью благодаря большому количество одного повторящегося у всей категории слова - например `джинсы` или *прерзервативы*.\n",
    "- а вот категории с маленьким количеством уникальных чеков и без отличительной какой-нибудь черты (достаточно было одного повторяющегося слова) разделялись плохо - были предприняты даже попытки разметить и добавить в недостающие категории товары, но это стало непосильной задачей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. `Использованные модели`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В плане выбора модели я не блистал оригинальностью, перепробоав всевозможные типичные методы, но приведу те, которые мне понравились по идее и/или результату. Перед применением данных моделей производилась предварительная предобработка текста, описанная в пункте `I`:\n",
    "\n",
    "1. (Идея) \n",
    "\n",
    "    - *TRAIN*: посчитать для каждой категории с помощью `Counter` из бибилотеки `collections` встречаемость каждого слова в определенной категории, создать словарь, в котором ключи - номер категории, а значения - словарь `counter` наиболее встречаемых слов в данном словаре (например, я брал `n=50`. Частоты нормируются и взвешиваются пропорциально встречаемости категории в тренировчном множестве\n",
    "    \n",
    "    - *TEST*: предобработать аналогично тренировочному множеству тестовойе множество, посчитать вероятность принадлежности определенной категории через суммму весов - взять категорию с наибольшей суммой весов\n",
    "    \n",
    "Иногда в соревнованиях выстреливали простые модели, но здесь результат был ужасным - лучший `0.6`.\n",
    "\n",
    "2. (Идея) на предобработанных лемматезированных текстах я подумал, что можно обучить известную модель `Word2Vec`, только на всех `8` миллионах чеках уникальных чеках, а затем построить эмбеддинги предложений как среднее эмбеддингов и числа слов, которые есть из предложения в эмбеддинге. Получились даже вполне хорошие эмбеддинги (код я оставлю внизу, чтобы можно было их пощупать, есть разделимость по категориям, но результат разочаровал - `KNN CLassifier 9_neighbours` с метрикой `cosine` - лучший результат `0.77`.\n",
    "\n",
    "3. (Результат) Предобработка текста + добавление цифр + получение прзнаков `TFIDF` со следующими параметрами:\n",
    "\n",
    "```python\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=800000, \n",
    "    ngram_range=(1, 6), \n",
    "    stop_words ='russian',\n",
    "    analyzer=\"char_wb\", \n",
    "    norm = 'l2'\n",
    ")```\n",
    "\n",
    "Над всем этим используется линейный `SVMCLassifier` и получаем результат - `0.844`. Обидно, когда не придумал нового.\n",
    "\n",
    "4. Были ещё и нейронные рекурретные сети, но лучше о них я рассказывать не буду..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Думаю, что по данному соревнованию я сделаю следующие выводы и наблюдения:\n",
    "\n",
    "    - предобработка текста очень важна и ею нужно заниматься (а ещё это очень прокачивает знание регулярных выражений)\n",
    "    - разметка малопредставленных категорий помогла бы улучшить качество модели\n",
    "    - в данной работе совершенно не использовалась информация о дне недели, цене, времени, поэтому хотелось бы в дальнейшем научиться строить модели, учитывая дополнительные признаки.\n",
    "\n",
    "Спасибо за соревнование, буду продолжать работать над идеями. А сейчас для дождавшихся - код :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V Дополнительно: код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для предобработки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from functools import lru_cache\n",
    "ru_lemmatizer = pymorphy2.MorphAnalyzer()\n",
    "@lru_cache(maxsize=10 ** 6)\n",
    "def lru_lemmatizer(word):\n",
    "    '''лемматизация'''\n",
    "    return ru_lemmatizer.parse(word)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(train_data, perevod, lemir, maslin, prazdnik, do_lemma=False):\n",
    "    '''\n",
    "    INPUT\n",
    "    \n",
    "    ---------\n",
    "    \n",
    "    train_data :: pd.Dataframe - исходные данные, необходимо, чтобы был столбец item_name\n",
    "    perevod :: словарь сокращений\n",
    "    lemir :: список принадлежности замороженным продуктам\n",
    "    maslin :: список принадлежности категории масляных банок и консервов\n",
    "    prazdnik :: список слов, подразумевающих отдых или праздник\n",
    "    do_lemma :: default=False, лемматизация слов в конце с помощью PyMorhy\n",
    "    \n",
    "    OUPTUT:\n",
    "    \n",
    "    vocab_large_dict :: словарь, ключи - уникальные значения train_data['item_name'], \n",
    "                                 значения - обработанная строка слов, слова отделены одиночным пробелом\n",
    "                                 \n",
    "    train_data :: новый DataFrame со столбцом preprocess\n",
    "    \n",
    "    '''\n",
    "    un_values = train_data['item_name'].value_counts()\n",
    "    print('STEP 1')\n",
    "    a = []\n",
    "    wd = {}\n",
    "    for i in list(un_values.keys()):\n",
    "        new = i.lower()\n",
    "        splitted = re.findall(r'(\\b[a-zA-Zа-яА-ЯеЁ_]+\\b)', new)\n",
    "        if splitted != []:\n",
    "            if splitted[0] == new:\n",
    "                if i.isupper():\n",
    "                    #print(i)\n",
    "                    wd[i] = {}\n",
    "                    wd[i]['done'] = 'maybe'\n",
    "                    wd[i]['word'] = i.lower()\n",
    "                elif len(re.split(\"(?=[А-ЯA-Z\\_])\", i)) >= 2:\n",
    "                    split = re.split(\"(?=[А-ЯA-Z\\_])\", i)[1:]\n",
    "                    if any([x.lower() for x in split if len(x) == 1 and x not in string.punctuation]):\n",
    "                        if ''.join(split[-3:]) == 'ИМП':\n",
    "                            wd[i] = {}\n",
    "                            wd[i]['done'] = 'yes'\n",
    "                            wd[i]['word'] = ' '.join([x.lower() for x in split if len(x) !=1] + ['ИМП'])\n",
    "                        else:\n",
    "                            wd[i] = {}\n",
    "                            wd[i]['done'] = 'no'\n",
    "                            wd[i]['word'] = ' '.join([x.lower() for x in split if len(x) !=1])\n",
    "                    else: \n",
    "                        wd[i] = {}\n",
    "                        wd[i]['done'] = 'yes'\n",
    "                        wd[i]['word'] = ' '.join([x.lower() for x in split if x not in string.punctuation])\n",
    "                else:\n",
    "                    a.append(i)\n",
    "            else:\n",
    "                a.append(i)\n",
    "        else:\n",
    "            a.append(i)\n",
    "    print('STEP 2')\n",
    "    b = []\n",
    "    wd_2 = {}\n",
    "    for i in a:\n",
    "        text = re.sub(r'[{}]'.format(string.punctuation), ' ', i)\n",
    "        splitted = re.findall(r'(\\b[a-zA-Zа-яА-ЯеЁ_]+\\b)', text)\n",
    "        sub3 = re.sub(r'(\\b[a-zA-Zа-яА-ЯеЁ_]+\\b)', ' ', text)\n",
    "        if ' '.join(splitted) == i:\n",
    "            new_word = []\n",
    "            for j in splitted:\n",
    "                if j in perevod.keys():\n",
    "                    new_word.append(perevod[j])\n",
    "                elif j.isupper():\n",
    "                    new_word.append(j.lower())\n",
    "                elif j.islower():\n",
    "                    new_word.append(j.lower())\n",
    "                else:\n",
    "                    split = re.split(\"(?=[А-ЯA-Z\\_])\", j)[1:]\n",
    "                    if split is not []:\n",
    "                        for x in split:\n",
    "                            new_word.append(x.lower())\n",
    "            #new_word\n",
    "            wd_2[i] = {}\n",
    "            wd_2[i]['done'] = 'maybe'\n",
    "            wd_2[i]['word'] = ' '.join(new_word)\n",
    "        else:\n",
    "            b.append(i)\n",
    "    print('STEP 3')\n",
    "    slahes = {}\n",
    "    wd_3 = {}\n",
    "    c = []\n",
    "    for i in b:\n",
    "        z = text.lower()\n",
    "        text = i.lower()\n",
    "        text = re.sub(r'[{}]'.format(''.join([x for x in string.punctuation if x not in ['/', '.', '-', \"'\"]])), ' ', text)\n",
    "        words = re.findall(r'\\b[a-zA-Zа-яА-ЯеЁ]+\\b', text)\n",
    "        new_word = re.findall(r'\\b[a-za-я]{1}/[a-za-я]{1}\\b', text)\n",
    "        sub3 = re.sub(r'\\b[a-zA-Zа-яА-ЯеЁ]+\\b', ' ', text)\n",
    "        if new_word != []:\n",
    "            for j in new_word:\n",
    "                if j in slahes.keys():\n",
    "                    slahes[j].append(text)\n",
    "                else:\n",
    "                    slahes[j] = []\n",
    "        if ' '.join(words) == text:\n",
    "            wd_3[i] = {}\n",
    "            wd_3[i]['done'] = 'maybe'\n",
    "            for u in new_word:\n",
    "                if u in perevod.keys():\n",
    "                    if any([u == x for x in ['т/в', 'п/в', 'пв', 'тв', 'vsop']]) and any([x in z for x in ['ml', 'м', 'мл', 'одек', \n",
    "                                                                                                           'одеколон', 'bruno', 'tentation', \n",
    "                                                                                                           'gracia', 'milady']]):\n",
    "                        if any([u == x for x in ['т/в', 'тв', 'vsop']]):\n",
    "                            words.append('туалетная вода')\n",
    "                        else:\n",
    "                            words.append('парфюмерная вода')\n",
    "                    else:\n",
    "                        words.append(perevod[l])\n",
    "                else:\n",
    "                    words.append(l)\n",
    "            wd_3[i]['word'] = ' '.join(words)\n",
    "        else:\n",
    "            c.append(i)  \n",
    "    print('STEP 4')\n",
    "    wd_4 = {}\n",
    "    num = 0\n",
    "    step4 = []\n",
    "    for i in c:\n",
    "        z = i.lower()\n",
    "        text = re.sub(r'[{}]'.format(string.punctuation), ' ', z)\n",
    "        words = re.findall(r'\\b[a-zA-Zа-яА-ЯеЁ]+\\b', text)\n",
    "        if re.search('\\d+', z) is None:\n",
    "            if ' '.join(words) == text:\n",
    "                w = re.split('[ ,]', z)\n",
    "                words = []\n",
    "                for u in w:\n",
    "\n",
    "\n",
    "                    if re.search(r'\\w{2,}[-]\\w{2,}|\\w{3,}[.]\\w{3,}|\\w{2,}\\/\\w{2,}', u) is not None:\n",
    "                        if u in perevod.keys():\n",
    "                            words.append(perevod[u])\n",
    "                        else:\n",
    "                            for l in re.split('[-.\\/]', u):\n",
    "                                if l in perevod.keys():\n",
    "                                    words.append(perevod[l])\n",
    "                                else:\n",
    "                                    words.append(l)\n",
    "                    else:\n",
    "                        if u in perevod.keys():\n",
    "                            words.append(perevod[u])\n",
    "\n",
    "                        elif re.search(r'\\bд/[a-zA-Zа-яА-ЯеЁ]+\\b', u) is not None:\n",
    "                            words.append('для ' + u.split('/')[-1])\n",
    "                        else:\n",
    "                            words.append(u)\n",
    "                wd_4[i] = {}\n",
    "                wd_4[i]['done'] = 'maybe'\n",
    "                wd_4[i]['word'] = ' '.join(words)\n",
    "                num +=1\n",
    "            else:\n",
    "                step4.append(i)\n",
    "        else:\n",
    "            step4.append(i)\n",
    "    print('STEP 5')\n",
    "    num = 0\n",
    "    step5 = []\n",
    "    wd_5 = {}\n",
    "    for i in step4:\n",
    "        z = i.lower()\n",
    "        # text = re.sub(r'[{}]'.format(string.punctuation), ' ', z)\n",
    "        words = re.findall(r'\\b[a-zA-Zа-яА-ЯеЁ]+\\b', z)\n",
    "        if re.search('\\d+', z) is None:\n",
    "            w = re.split('[\\(\\), .]', z)\n",
    "            words = []\n",
    "            for u in w:\n",
    "                if re.search(r'\\w{2,}[-]\\w{2,}|\\w{3,}[.]\\w{3,}|\\w{2,}\\/\\w{2,}|\\w{2,}[.,\\/]|\\(\\w{2,}\\)|\\(\\w{2,} \\w{2,}\\)', u) is not None:\n",
    "\n",
    "                    if u in perevod.keys():\n",
    "                        if any([u == x for x in ['т/в', 'п/в', 'пв', 'тв', 'vsop']]) and any([x in z for x in ['ml', 'м', 'мл', 'одек', \n",
    "                                                                                                           'одеколон', 'bruno', 'tentation', \n",
    "                                                                                                           'gracia', 'milady']]):\n",
    "                            if any([u == x for x in ['т/в', 'тв']]):\n",
    "                                words.append('туалетная вода')\n",
    "                            else:\n",
    "                                words.append('парфюмерная вода')\n",
    "                        else:\n",
    "                            words.append(perevod[u])\n",
    "                    else:\n",
    "                        for l in re.split('[-.\\/\\(\\)\\\\\" ]', u):\n",
    "                            if l in perevod.keys():\n",
    "                                if any([l == x for x in ['т/в', 'п/в', 'пв', 'тв', 'vsop']]) and any([x in z for x in ['ml', 'м', 'мл', 'одек', \n",
    "                                                                                                           'одеколон', 'bruno', 'tentation', \n",
    "                                                                                                           'gracia', 'milady']]):\n",
    "                                    if any([l == x for x in ['т/в', 'тв']]):\n",
    "                                        words.append('туалетная вода')\n",
    "                                    else:\n",
    "                                        words.append('парфюмерная вода')\n",
    "                                else:\n",
    "                                    words.append(perevod[l])\n",
    "                            else:\n",
    "                                words.append(l)\n",
    "                else:\n",
    "                    if u in perevod.keys():\n",
    "                        if any([u == x for x in ['т/в', 'п/в', 'пв', 'тв', 'vsop']]) and any([x in z for x in ['ml', 'м', 'мл', 'одек', \n",
    "                                                                                                           'одеколон', 'bruno', 'tentation', \n",
    "                                                                                                           'gracia', 'milady']]):\n",
    "                            if any([u == x for x in ['т/в', 'тв']]):\n",
    "                                words.append('туалетная вода')\n",
    "                            else:\n",
    "                                words.append('парфюмерная вода')\n",
    "                        else:\n",
    "                            words.append(perevod[u])\n",
    "\n",
    "                    elif re.search(r'\\bд/[a-zA-Zа-яА-ЯеЁ]+\\b', u) is not None:\n",
    "                        words.append('для ' + u.split('/')[-1])\n",
    "\n",
    "                    elif len(u) == 1:\n",
    "                        None\n",
    "                    else:\n",
    "                        words.append(u)\n",
    "            wd_5[i] = {}\n",
    "            wd_5[i]['done'] = 'maybe'\n",
    "            text = re.sub(r'[{}]'.format(string.punctuation), ' ', ' '.join(words))\n",
    "            if text.split() != []:\n",
    "                if text.split()[0].endswith('илин'):\n",
    "                    wd_5[i]['word'] = text.split()[0]\n",
    "                else:\n",
    "                    wd_5[i]['word'] = ' '.join([x for x in text.split()])\n",
    "            else:\n",
    "                wd_5[i]['word'] = i\n",
    "            num +=1\n",
    "        else:\n",
    "            step5.append(i)\n",
    "    print('STEP 6')\n",
    "    \n",
    "    sum_dict = {   \n",
    "    'аи': 'заправка автотранспорт топливо евро газовая колонка', \n",
    "    'k5': 'заправка безопасное топливо евро газовая колонка', \n",
    "        'к5': 'заправка безопасное топливо евро газовая колонка',\n",
    "    'а': 'заправка автотранспорт топливо евро газовая колонка', \n",
    "    '92': 'заправка бензин евро газовая колонка', \n",
    "    '95': 'заправка бензин евро газовая колонка', \n",
    "    '98': 'заправка бензин евро газовая колонка',\n",
    "    '95е': 'заправка бензин евро газовая колонка', \n",
    "    'аи92': 'заправка автотранспорт топливо бензин евро газовая колонка', \n",
    "    'трк': 'заправка топливо газовая колонка', \n",
    "        'бензин': 'бензин', \n",
    "        'автомобиль': 'автотранспорт', \n",
    "        'джет': 'джет', \n",
    "        'премимум': 'премиум', \n",
    "        'класс': 'класс', \n",
    "        'колонка': 'колонка'}\n",
    "    \n",
    "    sum_dict_category_9 = {'диз': 'дизельное', \n",
    "                       'топ': 'топливо', 'дт': 'дизельное топливо', \n",
    "                       'колонка': 'колонка', 'дизельное': 'дизельное', \n",
    "                       'суг': 'сниженные углеводороные газы дизельное топливо', \n",
    "                       'танеко': 'производитель дизельное топливо', \n",
    "                       'пбт': 'пропан бутан технический дизельное топливо', \n",
    "                       'k5': 'заправка дизельное топливо', 'е': 'межсезонное', \n",
    "                       'л': 'летнее', 'з': 'зимнее', \n",
    "                       'еврос': 'европейский', '92': 'вид топливо', 'к5': 'заправка дизельное топливо', \n",
    "                      'трк': 'заправка', 'tpk': 'заправка'}\n",
    "    \n",
    "    num = 0\n",
    "    step6 = []\n",
    "    wd_6 = {}\n",
    "   \n",
    "    for i in step5:\n",
    "        z = i.lower()\n",
    "        text = re.sub('\\d+', ' ', z)\n",
    "        #words = re.findall(r'\\b[a-zA-Zа-яА-ЯеЁ]+\\b', text)\n",
    "        words = []\n",
    "        s = \"[аи|а|a|aи]{1,}[- ][0-9]{2,}[\\w\\/]{1,}[- ][0-9]{2,}[- ]\\w\\d|[\\w\\/]{1,}[- ][0-9]{2,}-\\w\\d|[аи|а|a|aи]{1,}[0-9]{2,}-\\w\\d|[аи|а|a|aи]{1,}[0-9-]{2,}\"\n",
    "        if len(re.findall(r'{}'.format(s), z)) != 0:\n",
    "            s = \"[аи|а|a|aи]{1,}[- ][0-9]{2,}[\\w\\/]{1,}[- ][0-9]{2,}[- ]\\w\\d|[\\w\\/]{1,}[- ][0-9]{2,}-\\w\\d|[аи|а|a|aи]{1,}[-+ | 0-9]{2,}[0-9a-zа-я]{2,}|[аи|а|a|aи]{1,}[0-9]{2,}-\\w\\d|[аи|а|a|aи]{1,}[0-9-]{2,}|трк|бензин|автомобильный|джет|премиум|класс|колонка|95\"\n",
    "            new_wo = re.findall(r'{}'.format(s), z)\n",
    "            \n",
    "            for we in new_wo:\n",
    "                my = re.split('[\\(\\), /+-]', we)\n",
    "                for m in my:\n",
    "                    if m in sum_dict.keys():\n",
    "                        words.append(sum_dict[m])\n",
    "            wd_6[i] = {}\n",
    "            wd_6[i]['done'] = 'maybe'\n",
    "            wd_6[i]['word'] = ' '.join(words)\n",
    "            \n",
    "        \n",
    "        elif len(re.findall(r'{}'.format(\"дт[_ -]\\w{1,}[_ -]\\w\\d|дт[_ -]\\w{1,}|суг|пбт|трк|tpk|танеко\"), z)) != 0:\n",
    "            s = \"дт[_ -]\\w{1,}[_ -]\\w\\d|дт[_ -]\\w{1,}|трк|tpk|92|диз|топливо|дт|колонка|топ|дизельное|суг|танеко|пбт\"\n",
    "            new_wo = re.findall(r'{}'.format(s), z)\n",
    "            for we in new_wo:\n",
    "                my = re.split('[\\(\\), /+-]', we)\n",
    "                for m in my:\n",
    "                    if m in sum_dict_category_9.keys():\n",
    "                        words.append(sum_dict_category_9[m])\n",
    "            wd_6[i] = {}\n",
    "            wd_6[i]['done'] = 'maybe'\n",
    "            wd_6[i]['word'] = ' '.join(words)\n",
    "        \n",
    "        elif re.search('\\d+', text) is None:\n",
    "            w = re.split('[\\(\\), .]', text)\n",
    "            for u in w:\n",
    "                if re.search(r'\\w{2,}[-]\\w{2,}|\\w{3,}[.]\\w{3,}|\\w{2,}\\/\\w{2,}|\\w{2,}[.,\\/]|\\(\\w{2,}\\)|\\(\\w{2,} \\w{2,}\\)', u) is not None:\n",
    "\n",
    "                    if u in perevod.keys():\n",
    "                        words.append(perevod[u])\n",
    "                    else:\n",
    "                        for l in re.split('[-.\\/\\(\\)\\\\\" ]', u):\n",
    "                            if l in perevod.keys():\n",
    "                                if any([l == x for x in ['т/в', 'п/в', 'пв', 'тв', 'vsop']]) and any([x in z for x in ['ml', 'м', 'мл', 'одек', \n",
    "                                                                                                           'одеколон', 'bruno', 'tentation', \n",
    "                                                                                                           'gracia', 'milady']]):\n",
    "                                    if any([l == x for x in ['т/в', 'тв', 'vsop']]):\n",
    "                                        words.append('туалетная вода')\n",
    "                                    else:\n",
    "                                        words.append('парфюмерная вода')\n",
    "                                else:\n",
    "                                    words.append(perevod[l])\n",
    "                            else:\n",
    "                                words.append(l)\n",
    "                else:\n",
    "                    if any([u == x for x in ['т/в', 'п/в', 'пв', 'тв', 'vsop']]) and any([x in z for x in ['ml', 'м', 'мл', 'одек', \n",
    "                                                                                                           'одеколон', 'bruno', 'tentation', \n",
    "                                                                                                           'gracia', 'milady']]):\n",
    "                        if any([u == x for x in ['т/в', 'тв', 'vsop']]):\n",
    "                            words.append('туалетная вода')\n",
    "                        else:\n",
    "                            words.append('парфюмерная вода')\n",
    "                    elif u in perevod.keys():\n",
    "                            words.append(perevod[u])\n",
    "                    elif re.search(r'\\bд/[a-zA-Zа-яА-ЯеЁ]+\\b', u) is not None:\n",
    "                        words.append('для ' + u.split('/')[-1])\n",
    "\n",
    "                    elif len(u) == 1:\n",
    "                        None\n",
    "                    else:\n",
    "                        words.append(u)\n",
    "            wd_6[i] = {}\n",
    "            wd_6[i]['done'] = 'maybe'\n",
    "            text = re.sub(r'[{}]'.format(string.punctuation), ' ', ' '.join(words))\n",
    "            if text.split() != []:\n",
    "                if text.split()[0].endswith('илин'):\n",
    "                    wd_6[i]['word'] = text.split()[0]\n",
    "                else:\n",
    "                    wd_6[i]['word'] = ' '.join([x for x in text.split()])\n",
    "            else:\n",
    "                wd_6[i]['word'] = ' '.join(words)\n",
    "            num +=1\n",
    "        else:\n",
    "            step6.append(i)\n",
    "    LARGE_DICT = {}\n",
    "    for i in [wd, wd_2, wd_3, wd_4, wd_5, wd_6]:\n",
    "        LARGE_DICT.update(i)\n",
    "    vocab_large_dict = {k: ' '.join([' '.join((re.sub(r'[{}]'.format(string.punctuation + '№'), \n",
    "                                            '', \n",
    "                                            re.sub('k', 'к', x)).replace('\\\\', '')).split(' ')) for x in w['word'].split(' ')])\n",
    "                        for k, w in LARGE_DICT.items()}\n",
    "    \n",
    "    \n",
    "    vocab_large_dict = {k: ' '.join([re.sub('k', 'к', re.sub(r'[{}]'.format(string.punctuation), '', perevod[x] if x in perevod.keys() else x)) for x in w.split(' ')]) for k, w in vocab_large_dict.items()}\n",
    "    print('MAPPING....')\n",
    "    vocab_large_dict = {k: ' '.join(['кислота' if x == 'к' and x != w.split(' ')[-1] and w.split(' ')[w.split(' ').index(x) + 1] == 'та' else x for x in w.split(' ') if x != 'та']) for k, w in vocab_large_dict.items()}\n",
    "    vocab_large_dict = {k: ' '.join(['мороженое' if x == 'м' and x != w.split(' ')[-1] and w.split(' ')[w.split(' ').index(x) + 1] == 'е' else x for x in w.split(' ') if x != 'е']) for k, w in vocab_large_dict.items()}\n",
    "    vocab_large_dict = {k: ' '.join(['внутреннее применение' if x == 'вн' and x != w.split(' ')[-1] and w.split(' ')[w.split(' ').index(x) + 1] == 'пр' else x for x in w.split(' ') if x != 'пр']) for k, w in vocab_large_dict.items()}\n",
    "    vocab_large_dict = {k: ' '.join(['раствор' if x == 'р' and x != w.split(' ')[-1] and w.split(' ')[w.split(' ').index(x) + 1] == 'р' else x for x in w.split(' ')]) for k, w in vocab_large_dict.items()}\n",
    "    vocab_large_dict = {k: ' '.join(['спортивный тренировочный инвентарь силовые тренировки' if x == 'speed' and x != w.split(' ')[-1] and w.split(' ')[w.split(' ').index(x) + 1] == 'bag' else x for x in w.split(' ')]) for k, w in vocab_large_dict.items()}\n",
    "    vocab_large_dict = {k: ' '.join(['попкорн' if x == 'поп' and x != w.split(' ')[-1] and w.split(' ')[w.split(' ').index(x) + 1] == 'корн' else x for x in w.split(' ') if x != 'корн']) for k, w in vocab_large_dict.items()}\n",
    "    vocab_large_dict = {k: ' '.join([perevod[x] if x in perevod.keys() else x for x in w.split(' ')]) for k, w in vocab_large_dict.items()}\n",
    "    vocab_large_dict = {k: ' '.join(['праздник ' + x if x in prazdnik else x for x in w.split(' ')]) for k, w in vocab_large_dict.items()}\n",
    "    if do_lemma:\n",
    "        vocab_large_dict = {k: ' '.join([lru_lemmatizer(x) for x in w.split(' ')]) for k, w in vocab_large_dict.items()}\n",
    "        vocab_large_dict = {k: ' '.join([perevod[x] if x in perevod.keys() else x for x in w.split(' ')]) for k, w in vocab_large_dict.items()}\n",
    "    vocab_large_dict = {k: ' '.join(['замороженная продукция ' + x if x in lemir else x for x in w.split(' ')]) for k, w in vocab_large_dict.items()}\n",
    "    vocab_large_dict = {k: ' '.join(['консервная баночная продукция ' + x if x in maslin else x for x in w.split(' ')]) for k, w in vocab_large_dict.items()}\n",
    "    vocab_large_dict = {k: ' '.join(['праздник ' + x if x in prazdnik else x for x in w.split(' ')]) for k, w in vocab_large_dict.items()}\n",
    "    train_data['preprocess'] = train_data['item_name'].map(vocab_large_dict)\n",
    "    return vocab_large_dict, train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А далее мой словарь сокращений..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = set(['эскимо', 'пломбир', 'чебурек', 'чебупели', 'хинкали', \n",
    "   'вареник', 'вареники', 'блины', 'блинчики', 'бефстроганов', 'лазанья', 'лед', 'манты',\n",
    "     'мираторг', 'мороженое',  'пельмени', 'пломбир', 'рожок', \n",
    "         'стаканчик',  'булгур', 'сорбет', \n",
    "          'пельмени', 'чевапчичи',\n",
    "     'голубцы',  'брокколи'])\n",
    "maslin = set(['аджика', 'варенье', 'джем', 'желе', \n",
    "             'квашеная', 'консервы', 'лечо', 'маслины', 'мёд', 'оливки', 'паштет', 'сайра', \n",
    "              'повидло', 'фасоль', 'шпроты'])\n",
    "\n",
    "prazdnik = ['выходной', 'боулинг', 'бенгальский', 'аренда', 'пузыри', 'батут', 'шар', 'дискотека', \n",
    "           'безлимит', 'аттракцион', 'детский', 'городок', 'огни', 'бар', 'день', 'парк', 'вход', \n",
    "            'веселье', 'веселие', 'заезд', 'караоке', 'катание', 'лед', 'лёд', 'льду', 'петарды',\n",
    "           'катание', 'массовое', 'мыльные', 'радужные', 'хлопушка', 'подарок', 'поздравление', 'баня', 'залпы',\n",
    "           'свадьба', 'свеча', 'турист', 'мир', 'фейерверки', 'дым', 'фейерверк', 'шар', 'воздушный', 'юбилей', \n",
    "           'скидка', 'миллион']\n",
    "\n",
    "perevod = {'в/с': 'высший сорт', \n",
    "           'б/к': 'без костей', \n",
    "           'в/у': 'вакуумная упаковка', \n",
    "           'м/у': 'мягкая упаковка', \n",
    "           'с/к': 'сырокопченая', \n",
    "           'ж/б': 'жестяная банка', \n",
    "           'п/к': 'полукопченая', \n",
    "           'с/м': 'свежемороженый', \n",
    "           'ж/р': 'жевательная резинка', \n",
    "           'б/г': 'без головы', \n",
    "           'б/п': 'большая пачка',\n",
    "           'п/о': 'пленочная оболочка', \n",
    "           'з/п': 'зубная паста', \n",
    "           'с/б': 'стеклянная бутылка', \n",
    "           'х/к': 'холодное копчение', \n",
    "           'ц/о': 'целлофановая оболочка', \n",
    "           'б/а': 'безалокогольные', \n",
    "           'д/п': 'детское питание',  \n",
    "           'm/l': 'размер', \n",
    "           'з/щ': 'зубная щётка', \n",
    "           'п/ф': 'полуфабрикат', \n",
    "           'ветч/сыр': 'ветчина сыр', \n",
    "           'д/пола': 'для пола', \n",
    "           'д/уборки': 'для уборки', \n",
    "           'с/с': 'слабо соленая', \n",
    "           'охл': 'охлажденная', \n",
    "           'д/чист': 'для чистки', \n",
    "           'д/колки': 'для колки', \n",
    "           'н/р': 'неразделанный', \n",
    "           'д/кош': 'для кошки', \n",
    "           'туал': 'туалет', \n",
    "           'асс-те': 'ассортименте', \n",
    "           'пив': 'пивной', \n",
    "           'д/м': 'для мужчин', \n",
    "           'д/ж': 'для женщин', \n",
    "           'д/выпеч': 'для выпечки', \n",
    "           'ст': 'стандартный', \n",
    "           'стд': 'стандартный', \n",
    "           'картоф': 'картофель', \n",
    "           'порц': 'порция', \n",
    "           'бол': 'большая', \n",
    "           'бкомбо': 'большое комбо', \n",
    "           'скомбо': 'среднее комбо', \n",
    "           'пласт': 'пластиковый', \n",
    "           'ср': 'средний', \n",
    "           'мал': 'маленький', \n",
    "           'табачн': 'табачные', \n",
    "           'кокт': 'коктейль', \n",
    "           'асс': 'ассортименте', \n",
    "           'чл': 'чистая линия', \n",
    "           'р-ра': 'раствора', \n",
    "           'нап': 'напиток', \n",
    "           'энерг': 'энергетический', \n",
    "           'ябл': 'яблоко', \n",
    "           'фр': 'фрутелла', \n",
    "           'автом': 'автомобильная', \n",
    "           'шариков': 'шариковых', \n",
    "           'мрам': 'мраморной', \n",
    "           'гов': 'говядины', \n",
    "           'ОСТАН': 'останкинское', \n",
    "           'фил': 'филе', \n",
    "           'зап': 'запеченное', \n",
    "           'прод': 'продукт', \n",
    "           'йог': 'йогурт', \n",
    "           'устройс': 'устройство', \n",
    "           'арб': 'арбуз', \n",
    "           'дын': 'дыня', \n",
    "           'д/тетрад': 'для тетрадка', \n",
    "           'содерж-е': 'содержание', \n",
    "           'малин': 'малиновый', \n",
    "           'нач': 'начинка', \n",
    "           'кукур': 'кукуруза', \n",
    "           'карамел': 'карамель', \n",
    "           'мясн': 'мясной', \n",
    "           'смород': 'смородина', \n",
    "           'респуб': 'республика', \n",
    "           #'гр': 'грамм', \n",
    "           #'кг': 'килограмм', \n",
    "           #'шт': 'штук', 'руб': 'рубль', \n",
    "           'алког': 'алкоголь', \n",
    "           'п/сл': 'полусладкое', 'алк': 'алкоголь', 'фрукт': 'фруктовый', \n",
    "           'п/сух': 'полусухое', 'сух': 'сухое', 'кр': 'красное', 'вин': 'вино', \n",
    "           'сх': 'сухое', 'красн': 'красное', 'крас': 'красное', \n",
    "           'бел/сух': 'белое сухое', 'бут': 'бутылка',\n",
    "           #'шамп': 'шампанское',\n",
    "           'шампань': 'шампанское', \n",
    "           'шампусик': 'шампанское', 'бел': 'белое', \n",
    "           'ж/б': 'железная бутылка', 'б/алк': 'без алкоголь', \n",
    "           'б/сух': 'белое сухое', \n",
    "           'б': 'белое', 'светл': 'светлое', \n",
    "           'балтитка': 'балтика', 'шымкентское': 'шампанское', \n",
    "           'п/слад': 'полусладкое', 'жб': 'железная банка',\n",
    "           'н/ф': 'не фильтрованное', 'н\\ф': 'не фильтрованное', 'сл': 'сладкое', \n",
    "           'фильт': 'фильтрованное', 'нефильт': 'не фильтрованное', 'жив': 'живое', \n",
    "           'п/у': 'прозрачная упаковка', 'алко': 'алкоголь', 'глинтв': 'глинтвейн', \n",
    "           #'мл': 'миллиграмм',\n",
    "           'омсквинпром': 'оксимирон', \n",
    "           #'ml': 'миллиграмм', \n",
    "           'глинтв.': 'глинтвейн', 'п/с': 'полусладкое', \n",
    "           'ж\\б': 'железная банка', 'сп': 'спирт', 'спир': 'спирт', \n",
    "           'ш-е': 'шампанское', \n",
    "           'мягк': 'мягкое', 'н/фил': 'не фильтрованное', \n",
    "           'п/уп': 'пластиковая упаковка', 'стар': 'старый', 'бел/сух': 'белый сухой', 'игр': 'игристый', \n",
    "           'псх': 'полусухое', 'псл': 'полусладкое', \n",
    "           'блсх': 'белое сухое', 'кр/сух': 'красное сухое', 'крсх': 'красное сухое', 'водк': 'водка', \n",
    "           'с/а': 'слабо алкогольный', 'слабоалк': 'слабо алкогольный', \n",
    "           'слаб': 'слабый', 'слабоал': 'слабо алкогольный', 'ос': 'особая', \n",
    "           'бл': 'белое', 'рз': 'розовый', 'игр': 'игристое', \n",
    "           'газ': 'газированный', 'водакока': 'водка', 'боч': 'бочонок', \n",
    "           'бочон': 'бочонка', 'пивн': 'пивной', 'пив': 'пивной', \n",
    "           'през': 'презерватив', \n",
    "           'презер': 'презерватив', 'презерв': 'презерватив', \n",
    "           'conte': 'contex', 'cont': 'contex', 'дюрекс': 'durex', \n",
    "           'сверхтонк': 'сверхтонкие', 'смазк': 'смазка', 'ошибк': \n",
    "           'ошибка', 'контекс': 'contex', 'сиг': 'сигареты', \n",
    "           'классич': 'классический', 'ассорт': 'ассорти', \n",
    "           'сигаретывинстонблю': 'сигареты винстон блю', \n",
    "           'сигаретывинстонсильвер': 'сигареты винстон сильвер', \n",
    "           'таб': 'табак', 'сигаретылд': 'сигареты', \n",
    "           'сигаретытройка': 'сигареты тройка', \n",
    "           'сигаретыява': 'сигареты ява', 'l&m': 'LM', \n",
    "           'мрц': 'максимально розничная цена', \n",
    "           'силвер': 'сильвер', \n",
    "           'c-ты': 'сигареты', 'нагр': 'нагреваемые',\n",
    "           'нагрев': 'нагреваемые', 'табач': 'табак', \n",
    "           'жидк': 'жидкий', 'испар': 'испарение', \n",
    "           'масл': 'масляный', 'возд': 'воздушный', \n",
    "           'торм': 'тормозная', 'рем': 'ремень', 'д/ш': 'для шин', \n",
    "           'насад': 'насадка', 'автомоб': 'автомобиль', \n",
    "           'с/о': 'стеклоочистителя', 'со': 'стеклоочистителя', \n",
    "           'оч': 'стеклоочистителя', 'очист': 'стеклоочистителя', \n",
    "           'стеклоочис': 'стеклоочистителя', \n",
    "           'стеклооч': 'стеклоочистителя', 'а/м': 'ароматизатор', \n",
    "           'вел': 'велосипед', 'бескарк': 'бескаркасная', 'наб': 'набор', \n",
    "           'антиф': 'антифриз', 'аром': 'аромат', 'гермет': 'герметик', 'мот': 'моторное', \n",
    "           'жид-ть': 'жидкость', \n",
    "           'кан': 'канцелярский', 'унив': 'университет', 'тв': 'телевизор', \n",
    "           'жур': 'журнал', 'журн': 'журнал', 'ж-л': 'журнал', 'новос': 'новости', \n",
    "           'сканв': 'сканворды', 'настоль': 'настольных', 'канц': 'канцелярские', \n",
    "           'мелоч': 'мелочей','бейдж': 'бейджик', 'самокл': 'самоклеющаяся', \n",
    "           'быстросохн': 'быстро сохнущая', 'клейк': 'клейкая', 'колп': 'колпачок', \n",
    "           'цв': 'цвет', 'скоросшиват': 'скоросшиватель', \n",
    "           'карт': 'картонный', 'тетр': 'тетрадь', 'свидетел': 'свидетельство', 'заключ': 'заключение', \n",
    "           'скоросшив': 'скоросшиватель', 'цветн': 'цветные', \n",
    "           'каранд': 'карандаш', 'черн': 'черная', 'ч/г': 'чернографитный', \n",
    "           'ч/гр': 'чернографитный', 'платиковый': 'платиковый', 'руч': 'ручка', \n",
    "           'гел': 'гелевая', 'чер': 'черная', 'прост': 'простой', \n",
    "           'шарик': 'шариковый', 'н/р': 'набор ручек', 'нб': 'набор', 'прозр': 'прозрачный', 'колпач': 'колпачок',\n",
    "           'гелев': 'гелевая', 'капил': 'капиллярная', 'кап': 'капиллярная', 'син': 'синяя', 'чёрн': 'черная',\n",
    "          'дневн': 'дневник', 'обл': 'область', 'шк': 'школьная', 'кл': 'класс', 'ежед': 'ежедневник', \n",
    "           'ежедн': 'ежедневник', 'синт': 'синтетический', 'кар': 'карандаш', 'клейкарандаш': 'клей карандаш', \n",
    "          'рус/яз': 'русский язык', 'кист': 'кисточки', 'раб': 'рабочая', 'накл': 'наклейка', 'ножн': 'ножницы', \n",
    "           'днев': 'дневник', 'тет': 'тетрадь', 'универс': 'университет', 'проп': 'пропись', 'дошк': 'школьник', \n",
    "           'самоклбумагад': 'самоклеющаяся', 'пап': 'папка', 'отд': 'отделение', 'молн': 'молния', 'глянц': 'глянцевый', \n",
    "           'зел': 'зеленый', 'многоцв': 'много цветов', 'заточен': 'заточенный', 'худож': 'художник', 'акв': 'акварель', \n",
    "           'леп': 'лепения', 'фломаст': 'фломастер', 'разноцв': 'разноцветный', 'точилкимп': 'точилка', 'раск': 'раскраска',\n",
    "          'бумаа': 'бумага', 'аромапалочки': 'арома палочки', 'ароматичес': 'ароматический', 'аромнаб': 'арома', \n",
    "           'ароматич': 'ароматический', 'эфирн': 'эфирное', 'витамир': 'витамин', 'витаминно': 'витамин', \n",
    "           'капс': 'капсулы', 'аевитамины': 'витамины', 'вит': 'витамины', 'жев': 'жевательный', \n",
    "           'жеват': 'жевательный', 'к/та': 'кислота', 'обогащ': 'обогащенный', 'вита': 'витамин', 'актив': 'активный', \n",
    "          'красногорсклексредства': 'средства', 'стм': 'собственная торговая марка', 'дет': 'детская', 'трубоч': 'трубочка', \n",
    "           'подг': 'подгузник', 'подгузн': 'подгузник', \n",
    "           'клубн': 'клубничный', 'з/паста': 'зубная паста', 'туалетн': 'туалетное', 'п/заг': 'после загара', 'ручк': 'ручка',\n",
    "          'влаж': 'влажные', 'экстр': 'экстрат', 'салф': 'салфетка', 'косм': 'косметика', 'пен': 'пена','шам': 'шампунь', \n",
    "          'увл': 'увлажнение', 'нат': 'натуральный', 'взр': 'взрослый', 'пел': 'пеленка', \n",
    "           'пелен': 'пеленка', 'блест': 'блестящий', 'профилакт': 'профилактика', 'мес': 'месяц', 'сусп': 'суспензия', \n",
    "           'наз': 'назальные','назал': 'назальные', 'лексредства': 'лекарство средства', 'увлажняющ': 'увлажняющие', \n",
    "           'капс': 'капсулы', 'тбл': 'таблетки', 'водн': 'водный', 'вн/пр': 'внутреннее применение', 'внут': 'внутрь', \n",
    "           'табл': 'таблетки', 'наружн': 'наружное', 'прим': 'примение', 'р/ра': 'раствор', 'држ': 'драже', \n",
    "          'аэроз': 'аэрозоль', 'аэр': 'аэрозоль', 'к/ты': 'кислота', 'н/ка': 'настойка',  'р-ра': 'раствор',\n",
    "          'изготовл': 'изготовление', 'пластм': 'пластмассовая', 'оправе': 'оправа', 'конт': 'контактных', \n",
    "           'увлажн': 'увлажняющие', 'салфет': 'салфетка', 'auraвлсалф': 'салфетка', 'бум': 'бумага', \n",
    "           'влсалфунив': 'салфетка', 'проклад': 'прокладка', 'зп': 'зубная паста', 'полоск': 'полоскание', \n",
    "           'антиб': 'антибактериальный', 'ватн': 'ватные', 'вл': 'влажные', 'влажн': 'влажные', 'сал': 'салфетка', \n",
    "          'дез': 'дезодарант', 'невид': 'невидимый', 'муж': 'мужской', 'з/щетка': 'зубная щетка', 'з/щ': 'зубная щетка',\n",
    "          'мятн': 'мятный', 'прокл': 'прокладка', 'зуб': 'зубная', 'туалетнаябумага': 'туалентная бумага',\n",
    "           'туалет': 'туалетная', 'эл': 'электронная', 'тб': 'туалетная бумага', 'матир': 'матирующий', \n",
    "          'тон': 'тональный', 'косме': 'косметичка', 'подводк': 'подводка', 'удл': 'удлинить', 'снят': 'снятия', \n",
    "           'быстрыйэф': 'быстрый эффект', 'кальц': 'кальций', 'укре': 'укрепления', 'укреплен': 'укрепления', 'сн': 'снятия',\n",
    "          'компл': 'комплект', 'лит-ра': 'литература', 'кн': 'книга', \n",
    "           #'изд': 'издательство', \n",
    "           'сер': 'серия', 'уч': 'учебник', \n",
    "          'беременност': 'беременность', 'беременн': 'беременность', 'стер': 'стерильный', 'ant': 'антисептик', \n",
    "           'antisepti': 'антисептик', 'медиц': 'медицина', 'сте': 'стерильный', 'трубч': 'трубчатый', 'обув': 'обувь',\n",
    "          'марл': 'марлевый', 'марлев': 'марлевый', 'мед': 'медицина', 'повяз': 'повязка', 'л/пл': 'лейкопластырь',\n",
    "          'смотр': 'смотровые', 'стерил': 'стерильный', 'опр': 'опеделения', 'берем': 'беременность',\n",
    "          'одн': 'одноразовый', 'однор': 'одноразовый', 'однораз': 'одноразовый', 'лейкопл': 'лейкопластырь', \n",
    "           'изг-е': 'изготовление', 'мрт': 'магниторезонансная терапия', 'кт': 'компьютерная томография', \n",
    "           'орт': 'ортопед', 'спец': 'специальный', 'хир': 'хирургия', 'одек': 'одеколон', 'туал': 'туалетная', \n",
    "           'п/в': 'парфюмерная вода', 'сыв': 'сыворотка', 'кож': 'кожа', 'вол': 'волосы', 'массажн': 'массаж', \n",
    "           'прочи': 'прочее',\n",
    "            'шамп': 'шампунь', 'шп': 'шампунь', 'шампhs': 'шампунь', 'укреп': 'укрепление', 'золо': 'золотой',\n",
    "          'бальз': 'бальзам', 'ш-нь': 'шампунь', 'жир': 'жирные', 'ослаб': 'ослабленных', 'секущ': 'секущиеся',\n",
    "          'конд': 'кондиционер', 'кон': 'кондиционер', 'кондиц': 'кондиционер', 'бров': 'брови', 'сиян': 'сияние',\n",
    "          'трав': 'травы', 'перх': 'перхоть', 'шмп': 'шампунь', 'жем': 'жемчужина', 'умыв': 'умывания', \n",
    "          'сыворот': 'сыворотка', 'брит': 'бритья', 'очищ': 'очищающий', 'чж': 'черная жемчужина', 'черн': 'черный', \n",
    "          'скр': 'скраб', 'касеты': 'кассеты', 'ноч': 'ночной', 'дн': 'дневной', 'восстан': 'восстанавливающая', \n",
    "          'интенс': 'интенсивный', 'натур': 'натуральный', 'барх': 'бархатные', 'жен': 'женская', 'освежающ': 'освежающая',\n",
    "          'ж/мыло': 'женское мыло', 'д/рук': 'для рук', 'жид': 'жидкое', 'ванн': 'ванна', 'т/мыло': 'туалетное мыло',\n",
    "          'пиявк': 'пиявка', 'шер': 'шерсть', 'трик': 'трикотажные', 'брюкик': 'брюки', 'брюкир': 'брюки', \n",
    "          'женс': 'женские', 'мальч': 'мальчик', 'мужска': 'мужская', 'джинс': 'джинсы', 'полуб-ки': 'полуботинки',\n",
    "          'п/ботинки': 'полуботинки', 'рез': 'резина', 'сап': 'сапоги', 'ж': 'женская', 'д/об': 'для обуви', \n",
    "           'бюстгальт': 'бюстгальтер', 'бюст': 'бюстгальтер', 'бюстгалтер': 'бюстгальтер', 'колг': 'колготки',\n",
    "          'кол': 'колготки', 'колготкиtgb': 'колготки', 'колготы': 'колготки', 'трус': 'трусы', 'трусики': 'трусы',\n",
    "          'утепл': 'утепленный', 'футб': 'футболка', 'блуза': 'блузка', 'нос': 'носки',\n",
    "          'пиджакк': 'пиджак', 'пиджакр': 'пиджак', 'укороч': 'укороченный', 'комфорт': 'комфортный', 'диз': 'дизельное', \n",
    "           'зим': 'зимняя', 'элит': 'элитный', 'легг': 'легинсы', 'шор': 'шорты', 'ветчинагрибы': 'ветчина грибы', \n",
    "           'замор': 'замороженная', 'кус': 'кусочек', 'ветчин': 'ветчина', 'пиццааппетитная': 'пицца', \n",
    "           'пиццаветчина': 'пицца ветчина', 'пиццаролл': 'пицца ролл', 'выпеченн': 'выпеченный', 'моцарел': 'моцарелла',\n",
    "          'ветч': 'ветчина', 'pizza': 'пицца', 'pepperoni': 'пицца пепперони', 'capricciosa': 'пицца capricciosa', \n",
    "          'баварская': 'баварская пицца', 'пепперончини': 'пицца пепперони', 'пепперони': 'пепперони пицца', \n",
    "           'сыра': 'сыра пицца', 'телепицца': 'телепицца пицца', 'мексиканская': 'мексиканская пицца', \n",
    "           'капричеса': 'пицца капричеса', 'гавайская': 'гавайская пицца', 'филадельфия': 'филадельфия ролл', \n",
    "          'миниролл': 'мини ролл', 'копч': 'копченой', 'гамбургер': 'бургер', 'роял': 'роял бургер', \n",
    "           'роялбургер': 'роял бургер', 'сандвич': 'сэндвич', 'сендвич': 'сэндвич', 'фрешбургер': 'фреш бургер', \n",
    "           'шефбугер': 'шеф бургер', 'чикенсандвич': 'чикен сэндвич', 'шефбургер': 'шеф бургер', 'burger': 'бургер',\n",
    "          'кур': 'куриные', 'остр': 'острый', 'жаренн': 'жаренный', 'лук': 'луковые', 'клас-кие': 'классические',\n",
    "          'острмакнаггет': 'острые макнаггетс', 'свин': 'свинина', 'классик': 'классическая', 'тарел': 'тарелка',\n",
    "          'чик': 'чикен', 'бек': 'бекон', 'макнаггетс': 'мак наггетс', 'нагетсы': 'наггетсы',\n",
    "          'ланчбаскет': 'ланч баскет', 'ланчбокс': 'ланч бокс', 'штстрипсы': 'стрипсы', 'шткур': 'куриные', \n",
    "           'станд': 'стандартный', 'чикенбокс': 'чикен бокс', 'чикенбургер': 'чикен бургер', \n",
    "           'чикеннаггетсы': 'чикен наггетсы', 'чикенмак': 'чикен мак', 'чикенстар': 'чикен стар', \n",
    "           'чизбургер': 'чиз бургер сыр', 'макфреш': 'мак фреш', 'боксмастер': 'бокс мастер',\n",
    "          'америк': 'американо', 'ассам': 'чай ассам', 'американоg': 'американо', 'анчан': 'чай анчан',\n",
    "          'аффогато': 'кофе аффогато', 'capuccino': 'капучино', 'capuccino': 'капучино', 'бразил': 'бразильский',\n",
    "          'гляссе': 'кофе гляссе', 'латте': 'кофе латте', 'латтэ': 'кофе латте',\n",
    "           'капучино': 'кофе каппучино', 'американо': 'кофе американо',\n",
    "          'каппучино': 'кофе каппучино', 'капучиноg': 'каппучино', 'коф': 'кофе', 'напит': 'напиток', \n",
    "           'кортадо': 'кофе кортадо', 'мокко': 'кофе мокко', 'майский': 'майский чай', 'эспрессо': 'кофе эспрессо', \n",
    "           'эспресо': 'кофе эспрессо', 'мол': 'молоко', 'раф': 'раф кофе', 'розлив': 'розливной', 'раст': 'растительный',\n",
    "          'сенча': 'чай сенча','мокачино': 'кофе мокачино','моккачино': 'кофе мокачино', 'мокаччино': 'кофе мокачино',\n",
    "          'ройбуш': 'чай ройбуш', 'фкапучино': 'капучино', 'капуччино': 'кофе каппучино', 'капучинно': 'кофе каппучино',\n",
    "          'espresso': 'эспрессо', 'фраппе': 'кофе фраппе', 'рухуна': 'чай рухуна', 'амерекано': 'кофе американо',\n",
    "          'биф': 'бифштекс', 'картофе': 'картофель', \n",
    "           'аджапсандали': 'блюдо из баклажан помидор сладкий перец лук чеснок', \n",
    "           'акцияшашлык': 'акция шашлык', 'балоньезе': 'паста макароны', 'биточки': 'биточек', 'блинный': 'блин', \n",
    "           'фрик': 'фрикаделька', 'бризоль': 'курица мясо свинина сыр', 'гаспачо': 'суп пюре помидор огурец', \n",
    "           'блинчик': 'блин',\n",
    "           'доп': 'дополнительный', 'долма': 'виноград лист баранина масло свинина',\n",
    "          'морск': 'морской', 'жар': 'жареный', 'котл': 'котлета', 'котлет': 'котлета', 'свеж': 'свежей',\n",
    "          'фокачо': 'лепешка', 'фокача': 'лепешка', 'фокачча': 'лепешка', 'с-т': 'салат', 'с/т': 'салат', \n",
    "           'колб': 'колбаса', 'класс': 'классический', 'говяд': 'говядина', 'болоньезе': 'паста макароны', \n",
    "           'хрустящ': 'хрустящий', 'неж': 'нежный', 'дп': 'детское питание', 'черносл': 'чернослив', \n",
    "           'фрутоняня': 'фруто няня', 'земл': 'земляника', 'фрняня': 'фруто няня', 'детск': 'детский',\n",
    "          'яблклуб': 'яблоко клубника', 'перс': 'персик', 'лесн': 'лесные', 'биойог': 'био йогурт', 'фрук': 'фруктовые',\n",
    "          'фн': 'фруто няня', 'ф-н': 'фруто няня', 'спаг': 'спагетти макароны', 'молсмесь': 'молоко смесь',\n",
    "          'баблукпюре': 'бабушкино лукошко пюре', 'баб': 'бабушкино', 'овсян': 'овсяное', 'черни': 'черничный',\n",
    "          'молсмесьсимилакголд': 'молоко смесь симилак голд', 'неосвет': 'неосветленный', 'осветл': 'осветленный',\n",
    "          'биотв': 'био творог', 'биотворог': 'био творог', 'бзмж': 'без заменителя молочного жира', \n",
    "           'бзмжмороженое': 'бзмж мороженое', 'блинч': 'блинчики', 'заморож': 'замороженный', 'бульмени': 'пельмени',\n",
    "          'ваф': 'вафли', 'горяч': 'горячая', 'дес': 'десерт', 'краб': 'крабовые', 'змж': 'замороженный',\n",
    "          'м/е': 'мороженое', 'мират': 'мираторг', 'м-ное': 'мороженое', 'морож': 'мороженое', 'мор': 'мороженое',\n",
    "          'морожен': 'мороженое','мороженное': 'мороженое', 'карам': 'карамель', 'слоен': 'слоеное', 'стакан':'стаканчик',\n",
    "          'биомороженое': 'био мороженое', 'капутс': 'капуста', 'филев': 'филе', 'пельм': 'пельмени', 'цыпл': 'цыпленок',\n",
    "          'эск': 'эскимо', 'п/фаб': 'полуфабрикат', 'п/фабрикат': 'полуфабрикат', 'вар': 'вареная', \n",
    "          'в/к': 'великолужский', 'остан': 'останкино', 'сервел': 'сервелат', 'серв': 'сервелат',\n",
    "          'сос': 'сосика', 'сосис': 'сосиска', 'сард': 'сарделька', 'к-са': 'колбаса', 'грудинкаособаявк': 'грудинка особая',\n",
    "          'горох': 'горошек', 'горош': 'горошек', 'кваш': 'квашенная', 'квашеная': 'квашенная', 'конс': 'консервы',\n",
    "          'кукуруз': 'кукуруза', 'кук': 'кукуруза', 'олив': 'оливка', 'верм': 'вермишель',\n",
    "          'гречн': 'гречневая', 'каш': 'каша', 'овс': 'овсяная', 'кукруза': 'кукуруза', 'ячне': 'ячневая',\n",
    "          'лапш': 'лапша', 'макарон': 'макароны', 'разрыхлит': 'разрыхлитель','спагет': 'спагетти', \n",
    "           'макпр': 'макароны', 'мак/изд': 'макароны изделия','пшеничн': 'пшеничная', 'рж': 'ржаная', 'гречка': 'греча',\n",
    "          'гречневая': 'греча', 'рисовая': 'рис', 'быстр': 'быстрый', 'спагетти': 'макароны', 'фунчоза': 'макароны',\n",
    "          'кетч': 'кетчуп', 'ванильн': 'ванильный', 'горчич': 'горчица',\n",
    "          'подс': 'подсолнечное', 'подсол': 'подсолнечное', 'подсолн': 'подсолнечное', 'подсолнеч': 'подсолнечное',\n",
    "          'подсолне': 'подсолнечное', 'слив': 'сливочное', 'пасх': 'пасхальный', 'сахарн': 'сахар',\n",
    "          'наклейкнапасхальняйц': 'наклейка на пасхальные яйца', 'припр': 'приправа', 'повареная': 'поваренная',\n",
    "          'при/ва': 'приправа', 'при-ва': 'приправа', 'прип': 'приправа','топинг': 'топпинг', 'золот': 'золотая',\n",
    "          'злато': 'подсолнечное', 'молот': 'молотый', 'йогпит': 'йогурт питьевой', 'биойогурт': 'био йогурт',\n",
    "          'биогурт': 'био йогурт', 'пит': 'питьевой', 'биокефир': 'био кефир', 'биоваренец': 'био варенец',\n",
    "          'биоряж': 'био ряженка', 'биопродукт': 'био продукт', 'биоряженка': 'био ряженка','вкусн': 'вкусный',\n",
    "          'термост': 'термостатный', 'фруатэ': 'фруктовый', 'фрутис': 'фруктовый', 'фруттис':'фруктовый',\n",
    "          'натуральн': 'натуральный', 'клуб': 'клубника', 'кусоч': 'кусочек', 'греческ':'греческий', \n",
    "           'двухсл': 'двухслойный', 'клюкв': 'клюква', 'йогуртн': 'йогурт', 'йогуртнежн': 'йогурт нежный', \n",
    "          'йогуртнежныйперсикбзмж': 'йогурт нежный персик бзмж', 'йп': 'йогуртный продукт', 'кеф': 'кефир',\n",
    "          'жирн': 'жирный', 'пюр': 'пюре', 'молоч': 'молочный', 'молочн': 'молочный', 'шок': 'шоколад',\n",
    "          'м/з': 'майонез', 'м-з': 'майонез', 'майон': 'майонез', 'прованс': 'провансаль', 'прован':'провансаль',\n",
    "          'детс': 'детское', 'отборн': 'отборное', 'отбор': 'отборное', 'пастер': 'пастеризованное', \n",
    "           'паст': 'пастеризованное', 'сгущ': 'сгущенка', 'сах': 'сахар', 'ультрапаст': 'ультра пастеризованное',\n",
    "          'ультрап': 'ультра пастеризованное', 'ультр': 'ультра пастеризованное', 'ультроп': 'ультра пастеризованное',\n",
    "          'ультрапаст': 'ультра пастеризованное', 'ультрпаст': 'ультра пастеризованное',\n",
    "          'молокодомик': 'молоко домик', 'молокосод': 'молоко содержащий',  'молокосодерж': 'молоко содержащий',\n",
    "          'сгущен': 'сгущенка', 'стерилиз': 'стерилизованное', 'кисломол': 'кисло молочный', \n",
    "           'сзмж': 'содержит заменитель молочных жиров', 'смет': 'сметана',\n",
    "          'плав': 'плавленый', 'плавл': 'плавленый', 'плавлен': 'плавленый','российск': 'российский', \n",
    "          'россий': 'российский', 'глаз': 'глазированные', 'глазир': 'глазированные', 'глазиров': 'глазированные',\n",
    "          'суфл': 'суфле', 'твор': 'творожный', 'творож': 'творожный', 'темн': 'темный', 'легк': 'легкий',\n",
    "          'курин': 'куриное', 'цб': 'цыпленок бройлер', 'пф': 'полуфабрикат', 'шеи': 'шея', 'семеч': 'семечки',\n",
    "           'сем': 'семечки', 'рыбк': 'рыбка', 'принглс': 'чипсы', 'лейс': 'чипсы', 'яблоч': 'яблочные', \n",
    "           'читос': 'чипсы', 'чипсоны': 'чипсы', 'хруст': 'хрустящий', 'pringles': 'чипсы', 'lays': 'чипсы', \n",
    "           'хрустим' : 'сухарики', 'короч': 'корочки', 'чип': 'чипсы', 'nachos': 'чипсы', 'beerka': 'арахис',\n",
    "          'воронц': 'воронцовские', 'вял': 'вяленая', 'сопа': 'рыба сопа', 'сибас': 'рыба сибас',\n",
    "          'вобла': 'рыба вобла', 'кета': 'рыба кета', 'камбала': 'рыба камбала', 'горбуша': 'рыба горбуша', \n",
    "           'сельдь':'рыба сельдь', 'анчоус': 'рыба анчоус', 'балык': 'рыба балык', 'вомер': 'рыба вомер',\n",
    "          'дорада': 'рыба дорада', 'жерех': 'рыба жерех', 'голец': 'рыба голец', 'карп': 'рыба карп', \n",
    "           'килька': 'рыба килька', 'каракатица': 'рыба каракатица', 'карась': 'рыба карась', \n",
    "           'мореп': 'морепродукты', 'морепрод': 'морепродукты', 'морепродукт': 'морепродукты',\n",
    "          'морепр': 'морепродукты', 'сайда': 'рыба сайда', 'мин/вода': 'минеральная вода',\n",
    "           'мин-вода': 'минеральная вода', 'мин': 'минеральная', 'водаборжомистекло': 'вода боржоми стекло',\n",
    "          'водапитьевая': 'вода питьевая', 'негаз': 'негазированная', 'негазиров': 'негазированная',\n",
    "          'черног': 'черноголовка', 'минерал': 'минеральная', 'минер': 'минеральная', 'минеральн': 'минеральная',\n",
    "          'питьев': 'питьевая', 'aqua': 'вода аква минерале', 'minerale': 'вода аква минерале', 'borjomi': 'вода боржоми',\n",
    "          'анан': 'ананас', 'газир': 'газированная', 'свят': 'святой', 'г/в': 'газированная вода', \n",
    "           'газвода': 'газированная вода', 'энергетич': 'энергетический', 'энергет': 'энергетический', 'энер': 'энергетический', \n",
    "          'энег': 'энергетик', 'эн': 'энергетический', 'н/к': 'напиток', 'н-к': 'напиток', 'швеп': 'швепс лимонад', \n",
    "           'fuse': 'фьюз', 'tea': 'чай', 'минвода': 'минеральная вода', 'сокосод': 'сокосодержащий',\n",
    "          'сокосодер': 'сокосодержащий', 'сильногаз': 'сильногазированный', 'сокосодерж': 'сокосодержащий',\n",
    "          'шокол': 'шоколад', 'бат': 'батончик', 'ш-д': 'шоколад', 'ш/д': 'шоколад', 'ш': 'шоколад', 'холс': 'холлс',\n",
    "          'хлебобулочн': 'хлебобулочное', 'хлебобул': 'хлебобулочное', 'хлебо-булочное': 'хлебобулочное', \n",
    "           'хлебо/булочное': 'хлебобулочное', 'ржано': 'ржаной', 'пшенич': 'пшеничный', 'пш': 'пшеничный', 'пшен': 'пшеничный',\n",
    "          'бул': 'булка', 'х/б': 'хлебобулочное', 'изд': 'изделие', 'пир': 'пирог', 'печен': 'печенье', 'печ': 'печенье',\n",
    "          'круас': 'круассан', 'круасан': 'круассан', 'круасс': 'круассан', 'круасаны': 'круассан', 'конф': 'конфеты',\n",
    "          'зефирн': 'зефир', 'резина': 'резинка', 'марм': 'мармелад', 'свадебные': 'свадьба', \n",
    "           'танцпола': 'танцпол', 'диско': 'дискотека', 'празднич': 'праздник', 'пневмохлопушка': 'пневмо хлопушка', \n",
    "          'пневмохл': 'пневмо хлопушка', 'поздравл': 'поздравление', 'праздничные': 'праздник', \n",
    "           'праздничный': 'праздник', \n",
    "           'русскаябаня': 'русская баня', 'туристический': 'турист', 'вых': 'выходной', 'н-р': 'набор',\n",
    "          'хвс': 'холодное водоснабжение', 'вдго': 'внутридомовое газовое оборудование',\n",
    "          'вкго': 'внутриквартирное газовое оборудование', 'капремонт': 'капитальный ремонт',\n",
    "          'жбо': 'жидкие бытовые отходы', 'гвс': 'горячее водоснабжение', \n",
    "           'сои': 'содержание общедомового имущества', 'ор': 'общедомовые ресурсы', \n",
    "           'тко': 'твердые бытовые отходы', 'моп': 'места общего пользования', \n",
    "           'хв': 'холодное водоснабжение', 'мкд': 'многоквартиный дом', 'ду': 'управление дома',\n",
    "          'одн': 'общедомовые нужды', 'одпу': 'общедомовые приборы учета', 'гп': 'государственное предприятие',\n",
    "          'оди': 'общедомовые нужды', 'вгдо': 'внутридомовое газовое оборудование', \n",
    "           'жкх': 'жилищно коммунальное хозяйство', 'ои': 'общее имущество',\n",
    "          'ипу': 'индивидуальные приборы учета', 'квт': 'киловатт час',\n",
    "          'жку': 'жилищно коммунальные услуги', 'использ': 'использование', 'содерж': 'содержать', 'общ': 'общее',\n",
    "          'муп': 'муниципальное унитарное предприятие', 'НДС': 'налог на добавленную стоимость',\n",
    "          'соджилья': 'содержание жилья', 'пк': 'повыщающий коэффициент', 'дек': 'декабрь', 'окт': 'октябрь',\n",
    "          'апр': 'апрель', 'повыш': 'повышающий', 'нояб': 'ноябрь', 'отвед': 'отведение', 'обсл': 'обслуживание',\n",
    "          'квартплат': 'квартирная плата', 'элеснаб': 'электроснабжение', 'взросл': 'взрослый', \n",
    "           'ласты': 'бассейн ласты', 'протеиновый': 'протеиновый энергетический спортивное питание',\n",
    "          'chiкabar': 'энергетический протеиновый спортивное питание набор массы', \n",
    "          'monohydrate': 'смесь для ускорения роста мышц протеин спортивное питание заменитель набор массы',\n",
    "          'energon': 'энергетическое спортивное питание заменитель', 'чамп': 'энергетическое спортивное питание', \n",
    "          'белок': 'спортивное питание', 'фитнес': 'фитнес спортивный', 'smart': 'спортивное питание', \n",
    "           'eemb': 'энергетический протеиновый спортивное питание для спорта набор массы', \n",
    "           'eemm': 'энергетический протеиновый спортивное питание для спорта набор массы', \n",
    "           'nutrition': 'протетиновое спортивное питание', 'quest': 'энергетический протеивновый набор массы' , \n",
    "           'prot': 'спортивное питание заменитель', 'спортик': 'спортивное питание набор массы', 'турбослим': 'спортивное питание заменитель',\n",
    "          'соевый': 'спортивное питание заменитель', 'пребиосвит': 'спортивное питание заменитель',\n",
    "          'samyun': 'набор массы спортивное питание энергетическое', 'wan': 'спортивное питание', \n",
    "           'muscle': 'набор массы мускулы спортивное питание',\n",
    "          'alpinistiк': 'спортивный тренировочный инвентарь', \n",
    "           'трос': 'спортивный тренировочный инвентарь силовые тренировки',\n",
    "           'резинов': 'резиновая', 'скакалка': 'спортивный инвентарь для тренировок прыжки спорт',\n",
    "          'weight': 'спортивный тренировочный инвентарь силовые тренировки', \n",
    "           'weights': 'спортивный тренировочный инвентарь силовые тренировки',\n",
    "           'гантель': 'спортивный тренировочный инвентарь силовые тренировки', \n",
    "           'гантели': 'спортивный тренировочный инвентарь силовые тренировки',\n",
    "          'гимнастический': 'спортивный тренировочный инвентарь гимнастические тренировки', \n",
    "           'гимнастич': 'гимнастический', 'эспандер': 'спортивный тренировочный инвентарь гимнастические тренировки',\n",
    "          'training': 'спортивный тренировочный инвентарь силовые тренировки', \n",
    "          'обруч': 'спортивный тренировочный инвентарь гимнастические тренировки', \n",
    "          'тяга': 'спортивный тренировочный инвентарь силовые тренировки', 'рулевая': 'силовые тренировки',\n",
    "          'утяжелители': 'спортивный тренировочный инвентарь силовые тренировки', \n",
    "           'пластмасс': 'пластмассовый', 'silapro': 'спортивный тренировочный инвентарь',\n",
    "          'starfit': 'спортивный тренировочный инвентарь силовые тренировки', 'оберт':'обертка',\n",
    "          'пак': 'пакет', 'подар': 'подарок', 'творч': 'творчество', \n",
    "           'раскраска': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "         \n",
    "          'мелки': 'художественные принадлежности для творчества  и арт искусство рисование', \n",
    "          'скетчбук': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "          'фломастеры': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "          'фломастер': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "          'трафарет': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "         'разбавитель': 'художественные принадлежности для творчества  и арт искусство рисование', \n",
    "           'холст': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "          'раскр': 'раскраска', 'творчество': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "          'альбом': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "          'акварель': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "          'акрил': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "          'мольберт': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "          'акварель': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "          \n",
    "          'акварель': 'художественные принадлежности для творчества  и арт искусство рисование',\n",
    "          'кистей': 'художественные принадлежности для творчества  и арт искусство рисование', \n",
    "          'держат': 'держатель', 'магнит': 'магнитный', 'реш': 'решетка',\n",
    "          'гофра': 'трубчатые строительные материалы сантехника', \n",
    "           'аэратор': 'трубчатые строительные материалы сантехника', \n",
    "           'втулка': 'трубчатые строительные материалы сантехника', \n",
    "          'сифон': 'трубчатые строительные материалы сантехника', \n",
    "           'гофрированный': 'трубчатые строительные материалы сантехника',\n",
    "          'смеситель': 'трубчатые строительные материалы сантехника', \n",
    "          'клапан': 'трубчатые строительные материалы сантехника', \n",
    "           'гофротрубка': 'трубчатые строительные материалы сантехника',\n",
    "          'кран': 'трубчатые строительные материалы сантехника', 'сантехника': 'трубчатые строительные материалы сантехника',\n",
    "          'шланг': 'трубчатые строительные материалы сантехника',\n",
    "          'унитаза': 'трубчатые строительные материалы сантехника', \n",
    "           'стоки':'трубчатые строительные материалы сантехника', 'cифон': 'трубчатые строительные материалы сантехника',\n",
    "          'сантех':'трубчатые строительные материалы сантехника', 'излив': 'трубчатые строительные материалы сантехника',\n",
    "          'арматура': 'трубчатые строительные материалы сантехника','умывальник':'трубчатые строительные материалы сантехника',\n",
    "          'лейка': 'трубчатые строительные материалы сантехника','дюб': 'дюбель'}\n",
    "# шамп: шампунь шампанское"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так мы получаем предобработанный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_, tr_, = prepare(train, perevod, l, maslin, prazdnik, do_lemma=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так мы обучаем `Word2Vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_tokemizer = {k: w.split(' ') for k, w in enumerate(tr_['preprocess'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(list(vocab_tokemizer.values()), # data for model to train on\n",
    "                 size=300,         # embedding vector size\n",
    "                 min_count=7,     # consider words that occured at least 5 times\n",
    "                 window=7).wv     # define context as a 3-word window around the target word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('word2vec', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откроем обученный нами `word2vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pickle.load(open('word2vec', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем эмбеддинги предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_vec(question, embeddings, dim=300, first=True):\n",
    "    \"\"\"\n",
    "        question: строка\n",
    "        embeddings: наше векторное представление\n",
    "        dim: размер любого вектора в нашем представлении\n",
    "        \n",
    "        return: векторное представление для вопроса\n",
    "    \"\"\"\n",
    "    words = question.split(' ') #your code\n",
    "    # убрать знак вопроса, если он есть\n",
    "    n_known = 0\n",
    "    result = np.array([0] * dim, dtype=float)\n",
    "    \n",
    "    if first:\n",
    "        word = words[0]\n",
    "        if word in embeddings:\n",
    "            result += embeddings[word] #your code\n",
    "            n_known += 1\n",
    "    else:\n",
    "        for word in words:\n",
    "            if word in embeddings:\n",
    "                result += embeddings[word] #your code\n",
    "                n_known += 1\n",
    "            \n",
    "    if n_known != 0:\n",
    "        return result / n_known #your code\n",
    "    else:\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1\n",
      "STEP 2\n",
      "STEP 3\n",
      "STEP 4\n",
      "STEP 5\n",
      "STEP 6\n",
      "MAPPING....\n"
     ]
    }
   ],
   "source": [
    "unique_items = train_data.drop_duplicates('item_name')\n",
    "dct2_, tr2_, = prepare(unique_items, perevod, l, maslin, prazdnik, do_lemma=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры предобработки текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Спинки варено-копченые из мяса ЦБ в/у охладенные',\n",
       " 'спинки варено копченые из мяса цыпленок бройлер вакуумная упаковка охладенные')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_items.loc[72]['item_name'], unique_items.loc[72]['preprocess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Брюки трик. женские', 'брюки трикотажные женские')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_items.loc[221]['item_name'], unique_items.loc[221]['preprocess']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полуичим эмбеддинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X = np.array([question_to_vec(question=question, embeddings=m, dim=300, first=False) for question in tr2_['preprocess']])\n",
    "y = unique_items['category_id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим таблицу эмбеддингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(np.concatenate((X, \n",
    "                                   tr2_[['receipt_dayofweek', 'item_quantity', 'item_price', 'item_nds_rate']].values, \n",
    "                                   y[:, np.newaxis]), axis=1))\n",
    "columns = [f'feature_{x}' for x in np.arange(0, 300)] + \\\n",
    "['receipt_dayofweek', 'item_quantity', 'item_price', 'item_nds_rate'] + \\\n",
    "['category_id']\n",
    "dat.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_295</th>\n",
       "      <th>feature_296</th>\n",
       "      <th>feature_297</th>\n",
       "      <th>feature_298</th>\n",
       "      <th>feature_299</th>\n",
       "      <th>receipt_dayofweek</th>\n",
       "      <th>item_quantity</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_nds_rate</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054561</td>\n",
       "      <td>-0.392966</td>\n",
       "      <td>0.410688</td>\n",
       "      <td>0.116836</td>\n",
       "      <td>0.989019</td>\n",
       "      <td>1.157157</td>\n",
       "      <td>1.632287</td>\n",
       "      <td>-0.352680</td>\n",
       "      <td>-0.509084</td>\n",
       "      <td>0.689676</td>\n",
       "      <td>...</td>\n",
       "      <td>1.274330</td>\n",
       "      <td>-1.676105</td>\n",
       "      <td>-0.193540</td>\n",
       "      <td>1.174354</td>\n",
       "      <td>0.899041</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.376635</td>\n",
       "      <td>-1.049812</td>\n",
       "      <td>1.021654</td>\n",
       "      <td>-0.610256</td>\n",
       "      <td>-0.561202</td>\n",
       "      <td>-0.090528</td>\n",
       "      <td>1.225579</td>\n",
       "      <td>0.942012</td>\n",
       "      <td>-0.220868</td>\n",
       "      <td>1.147172</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.592884</td>\n",
       "      <td>-1.578708</td>\n",
       "      <td>0.510537</td>\n",
       "      <td>-0.795046</td>\n",
       "      <td>0.296348</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020388</td>\n",
       "      <td>-1.286427</td>\n",
       "      <td>0.521235</td>\n",
       "      <td>-1.633261</td>\n",
       "      <td>0.155876</td>\n",
       "      <td>-0.660067</td>\n",
       "      <td>0.093485</td>\n",
       "      <td>0.784330</td>\n",
       "      <td>0.392229</td>\n",
       "      <td>-0.063603</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.068598</td>\n",
       "      <td>-1.367852</td>\n",
       "      <td>-0.088262</td>\n",
       "      <td>-1.153419</td>\n",
       "      <td>0.858392</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.993593</td>\n",
       "      <td>0.944048</td>\n",
       "      <td>-0.093030</td>\n",
       "      <td>-0.828796</td>\n",
       "      <td>-0.848058</td>\n",
       "      <td>0.692314</td>\n",
       "      <td>0.216841</td>\n",
       "      <td>-1.680906</td>\n",
       "      <td>-1.517059</td>\n",
       "      <td>-0.495888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079874</td>\n",
       "      <td>0.545516</td>\n",
       "      <td>0.435811</td>\n",
       "      <td>-0.417459</td>\n",
       "      <td>0.429165</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.044952</td>\n",
       "      <td>0.706317</td>\n",
       "      <td>0.509403</td>\n",
       "      <td>0.475204</td>\n",
       "      <td>1.119540</td>\n",
       "      <td>1.249804</td>\n",
       "      <td>1.099545</td>\n",
       "      <td>-0.517986</td>\n",
       "      <td>-0.934430</td>\n",
       "      <td>0.830007</td>\n",
       "      <td>...</td>\n",
       "      <td>1.256626</td>\n",
       "      <td>-0.397411</td>\n",
       "      <td>0.466691</td>\n",
       "      <td>0.839089</td>\n",
       "      <td>0.332216</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0   0.054561  -0.392966   0.410688   0.116836   0.989019   1.157157   \n",
       "1   0.376635  -1.049812   1.021654  -0.610256  -0.561202  -0.090528   \n",
       "2   0.020388  -1.286427   0.521235  -1.633261   0.155876  -0.660067   \n",
       "3  -0.993593   0.944048  -0.093030  -0.828796  -0.848058   0.692314   \n",
       "4   1.044952   0.706317   0.509403   0.475204   1.119540   1.249804   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  ...  feature_295  feature_296  \\\n",
       "0   1.632287  -0.352680  -0.509084   0.689676  ...     1.274330    -1.676105   \n",
       "1   1.225579   0.942012  -0.220868   1.147172  ...    -1.592884    -1.578708   \n",
       "2   0.093485   0.784330   0.392229  -0.063603  ...    -1.068598    -1.367852   \n",
       "3   0.216841  -1.680906  -1.517059  -0.495888  ...    -0.079874     0.545516   \n",
       "4   1.099545  -0.517986  -0.934430   0.830007  ...     1.256626    -0.397411   \n",
       "\n",
       "   feature_297  feature_298  feature_299  receipt_dayofweek  item_quantity  \\\n",
       "0    -0.193540     1.174354     0.899041                6.0            2.0   \n",
       "1     0.510537    -0.795046     0.296348                4.0            1.0   \n",
       "2    -0.088262    -1.153419     0.858392                4.0            1.0   \n",
       "3     0.435811    -0.417459     0.429165                5.0            1.0   \n",
       "4     0.466691     0.839089     0.332216                3.0            1.0   \n",
       "\n",
       "   item_price  item_nds_rate  category_id  \n",
       "0         8.0            2.0         78.0  \n",
       "1         4.0            1.0         71.0  \n",
       "2         4.0            1.0         71.0  \n",
       "3        12.0            1.0         70.0  \n",
       "4         7.0           -1.0         84.0  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом можно обучать модели, например `KNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "folds = KFold(8, \n",
    "              shuffle=True, \n",
    "              random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = cross_val_predict(knn, \n",
    "                             X, \n",
    "                             y, \n",
    "                             cv=folds, \n",
    "                             n_jobs=8, \n",
    "                             method='predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7549749233089824\n"
     ]
    }
   ],
   "source": [
    "score = f1_score(y, predicts, average='weighted')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим вообще на эмбеддинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ряженка', 0.718873143196106),\n",
       " ('варенец', 0.58260178565979),\n",
       " ('снежок', 0.4844396710395813),\n",
       " ('ультрапастеризованное', 0.46592074632644653),\n",
       " ('биоматрикс', 0.4627859890460968),\n",
       " ('простокваша', 0.43150943517684937),\n",
       " ('бифидок', 0.40915602445602417),\n",
       " ('питьевое', 0.39816442131996155),\n",
       " ('кефирный', 0.3964994251728058),\n",
       " ('пастеризованное', 0.38972562551498413)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.most_similar('кефир')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('болт', 0.7063924074172974),\n",
       " ('шпилька', 0.5963376760482788),\n",
       " ('гайкой', 0.5931398868560791),\n",
       " ('шплинт', 0.5835789442062378),\n",
       " ('резьбовая', 0.581788957118988),\n",
       " ('оцинкованная', 0.5693467855453491),\n",
       " ('din', 0.561095118522644),\n",
       " ('контргайка', 0.5568018555641174),\n",
       " ('гровер', 0.5169054269790649),\n",
       " ('нейлоновой', 0.5123203992843628)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.most_similar('гайка')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVMClassifier + TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так мы делаем предсказание с помощью модели из пункта `III.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1\n",
      "STEP 2\n",
      "STEP 3\n",
      "STEP 4\n",
      "STEP 5\n",
      "STEP 6\n",
      "MAPPING....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shiro\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:373: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\shiro\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "unique_items = train_data.drop_duplicates('item_name')\n",
    "d, x =  prepare(unique_items, perevod, l, maslin, prazdnik, do_lemma=False)\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=800000, \n",
    "    ngram_range=(1, 6), \n",
    "    stop_words ='russian',\n",
    "    analyzer=\"char_wb\", \n",
    "    norm = 'l2'\n",
    ")\n",
    "\n",
    "x['new'] = x['preprocess'] + ' ' + x['item_name']\n",
    "X_train = tfidf.fit_transform(x.new)\n",
    "y_train = x['category_id']\n",
    "clf = LinearSVC(cl)\n",
    "folds = KFold(8, \n",
    "              shuffle=True, \n",
    "              random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = cross_val_predict(clf, \n",
    "                             X_train, \n",
    "                             y_train, \n",
    "                             cv=folds, \n",
    "                             n_jobs=8, \n",
    "                             method='predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('new_sol_2/clf_task1', 'wb'))\n",
    "pickle.dump(tfidf, open('new_sol_2/tfidf', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.845884989392697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "score = f1_score(y_train, predicts, average='weighted')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      2356\n",
      "           1       0.93      0.89      0.91        28\n",
      "           2       0.97      0.89      0.92       316\n",
      "           3       0.88      0.87      0.88       109\n",
      "           4       0.70      0.64      0.67       225\n",
      "           6       0.55      0.38      0.44        64\n",
      "           7       0.94      0.98      0.96       224\n",
      "           9       0.90      0.98      0.94       104\n",
      "          11       0.60      0.53      0.56        47\n",
      "          12       0.78      0.69      0.73       182\n",
      "          13       0.71      0.59      0.65        37\n",
      "          19       0.74      0.50      0.60        74\n",
      "          20       0.98      0.88      0.93        59\n",
      "          24       0.65      0.47      0.55        68\n",
      "          26       0.20      0.09      0.13        22\n",
      "          27       0.72      0.68      0.70        38\n",
      "          29       0.78      0.89      0.83       129\n",
      "          30       0.78      0.75      0.77       296\n",
      "          31       0.39      0.18      0.25        38\n",
      "          35       0.88      0.60      0.71        25\n",
      "          36       0.82      0.65      0.72       189\n",
      "          37       0.73      0.52      0.60       124\n",
      "          38       0.92      0.96      0.94      2269\n",
      "          39       0.93      0.64      0.76        42\n",
      "          40       0.79      0.85      0.82       552\n",
      "          41       0.71      0.43      0.54        79\n",
      "          42       0.73      0.61      0.67        95\n",
      "          43       0.91      0.83      0.87       304\n",
      "          45       0.84      0.83      0.83       312\n",
      "          46       0.83      0.33      0.48        15\n",
      "          49       0.84      0.81      0.83       308\n",
      "          50       0.71      0.73      0.72       218\n",
      "          51       0.73      0.67      0.70       323\n",
      "          52       0.73      0.76      0.75       236\n",
      "          53       0.95      0.98      0.96       126\n",
      "          54       0.84      0.83      0.84        89\n",
      "          55       1.00      1.00      1.00        47\n",
      "          56       0.86      0.71      0.77        34\n",
      "          57       0.87      0.85      0.86       246\n",
      "          58       1.00      0.99      0.99        67\n",
      "          60       0.95      0.89      0.92       180\n",
      "          61       0.88      0.90      0.89      1058\n",
      "          62       0.82      0.79      0.81       155\n",
      "          66       0.88      0.92      0.90       237\n",
      "          67       0.83      0.88      0.86       306\n",
      "          68       0.84      0.87      0.85       175\n",
      "          69       0.83      0.77      0.80       441\n",
      "          70       0.84      0.89      0.86       887\n",
      "          71       0.81      0.83      0.82      4771\n",
      "          72       0.87      0.79      0.83       288\n",
      "          73       0.86      0.78      0.82      1109\n",
      "          74       0.90      0.91      0.90      1011\n",
      "          75       0.83      0.80      0.81       742\n",
      "          76       0.87      0.83      0.85       568\n",
      "          77       0.85      0.85      0.85      1190\n",
      "          78       0.93      0.95      0.94      2869\n",
      "          79       0.76      0.78      0.77       815\n",
      "          80       0.87      0.92      0.89      1850\n",
      "          81       0.87      0.87      0.87      1134\n",
      "          82       0.79      0.80      0.79       547\n",
      "          83       0.92      0.94      0.93      2865\n",
      "          84       0.91      0.95      0.92      7094\n",
      "          85       0.85      0.76      0.80       674\n",
      "          90       0.48      0.50      0.49        50\n",
      "          92       0.83      0.81      0.82       149\n",
      "          96       0.62      0.56      0.59        45\n",
      "          97       0.83      0.38      0.53        13\n",
      "         100       0.71      0.36      0.48        14\n",
      "         101       0.60      0.53      0.56        17\n",
      "         102       0.65      0.79      0.71        19\n",
      "         103       0.70      0.44      0.54        96\n",
      "         105       0.66      0.58      0.61       132\n",
      "         106       0.61      0.39      0.47        36\n",
      "         107       0.71      0.70      0.71       235\n",
      "         108       0.74      0.65      0.70        75\n",
      "         109       0.80      0.72      0.76       230\n",
      "         111       0.50      0.67      0.57        58\n",
      "         114       0.69      0.64      0.66       433\n",
      "         115       0.69      0.64      0.67       169\n",
      "         117       0.83      0.83      0.83       533\n",
      "         118       0.62      0.68      0.65       314\n",
      "         120       0.73      0.59      0.65       314\n",
      "         128       0.82      0.83      0.83        90\n",
      "         130       0.81      0.86      0.83       877\n",
      "         133       0.77      0.72      0.75       178\n",
      "         138       0.71      0.49      0.58        91\n",
      "         139       0.73      0.71      0.72       551\n",
      "         140       0.74      0.52      0.61       331\n",
      "         145       0.95      0.93      0.94       480\n",
      "         150       0.85      0.65      0.74        81\n",
      "         163       0.51      0.65      0.57        43\n",
      "         164       0.63      0.36      0.46        74\n",
      "         167       0.74      0.53      0.62        91\n",
      "         177       0.76      0.73      0.75       119\n",
      "         203       0.70      0.51      0.59        59\n",
      "         204       0.52      0.51      0.51      1146\n",
      "\n",
      "    accuracy                           0.85     48225\n",
      "   macro avg       0.78      0.71      0.74     48225\n",
      "weighted avg       0.85      0.85      0.85     48225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, predicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что есть отличная разделимость примерно половины классов, но на ухудшают результат очень плохо разделимые классые - например класс `26` - органайзеры, ножницы, бумага - очень перекрывающиеся c другими классами. В этом и проблема представления `tfidf` - контекст и порядок слов не учитываются. Поэтому, нужно применять другие модели. А какие - узнаем у победителей.\n",
    "\n",
    "Спасибо!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
